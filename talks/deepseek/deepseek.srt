1
00:00:00,620 --> 00:00:01,777
Ok我开始了。

2
00:00:01,777 --> 00:00:05,482
好，让那个雨生啊嗯那雨生要开场一下。

3
00:00:05,482 --> 00:00:10,576
不对，这个今天谢谢各位啊，这个基本上都是老朋友哈。

4
00:00:10,576 --> 00:00:17,059
然后来了真的跟我们一起跟张涛一起来这个进第三次集体学习啊。

5
00:00:17,059 --> 00:00:21,227
之前在真德我们一起学了这个啊学AI coding。

6
00:00:21,227 --> 00:00:34,888
其实每一次我觉得都是在一个技术变革刚刚发刚刚开始的时候，然后其张涛非常好的深入浅出的这个这个讲法，就给大家带来了很多的启发。

7
00:00:34,888 --> 00:00:39,287
然后过去的一个月呢其实特别特别精彩对吧？

8
00:00:39,287 --> 00:00:47,318
那肯定是这个出现啊带给大家特别多的惊喜，同时有特别多的这个呃这个各种不一样的角度去看额外对吧？

9
00:00:47,318 --> 00:00:55,000
就是有人从中美的角度，有人从开源意员的角度，有人从L的角度，有人有人从这个呃大大投入和小投入的角度。

10
00:00:55,000 --> 00:00:57,505
同时也有很多是是而非的信息，对吧？

11
00:00:57,505 --> 00:01:04,519
那这个大家看到有各种各样的这个到到底是觉得这个预训练不存在了，还是因为大家没有能看，对吧？

12
00:01:04,519 --> 00:01:10,364
所以不管这个舆论市场、二级市场啊，还有这个真是政治上都有特别多的这个波动啊。

13
00:01:10,364 --> 00:01:16,321
所以这个过程中呢，其实这个杨绍涛和pe他们在莫妮卡其实这个基本春节也没有休息。

14
00:01:16,321 --> 00:01:25,734
但是我看见很多AI的这个圈内人，春节也都没有休息，都在做大量的这个学习和思考啊，所以正好在这是开年后的第一个休息日是吧？

15
00:01:25,734 --> 00:01:32,066
第一个周日啊，那么张涛呃和和pe一起他们来给大家做这样的他们对阿万的这样的赏析吧。

16
00:01:32,066 --> 00:01:40,624
啊因为确实这个世界这工作非常非常厉害，然后同时这里面有很多这个到底是怎么回事，我希望跟大家一起交流探讨啊。

17
00:01:40,624 --> 00:01:47,128
那么郑哥反能也这个作为莫投资人，然后也作为这个一直以来后做这样一个学习活动，对吧？

18
00:01:47,128 --> 00:01:48,497
也也也也非常高兴。

19
00:01:48,497 --> 00:02:05,837
所以今天我们的C O安娜这个这个也也和我们很很多同事也一起在线下线上去学习啊，今天还请到了我们很多这个除了我们原来产品经理的这个群体外，投资圈的大咖，比如斌哥，对还有对对这个也有大家真的是非常非常热爱学习的一群人。

20
00:02:05,837 --> 00:02:07,506
好，反正我就话不多说啊。

21
00:02:07,506 --> 00:02:08,507
让他就开始了。

22
00:02:08,507 --> 00:02:15,516
行好，然后呢那个其实我相信大家在那个整个春节，包括我自己，我们今年春节在北京和上海两地过的。

23
00:02:15,516 --> 00:02:19,520
然后雪姐基本上就看过，抱着手机就没有放过，全程都在刷。

24
00:02:19,520 --> 00:02:24,360
就是不管是看那个美国的，就是白天看国内的反应，晚上看美国的反应。

25
00:02:24,360 --> 00:02:25,752
呃，线线上麻烦记下音。

26
00:02:25,752 --> 00:02:28,227
哎，对，然后基本上整个春节都这样过的。

27
00:02:28,227 --> 00:02:36,425
然后呢，春节之后这一周，我相信大家现在在各种各样的微信公众号或者各种各样地方已经刷了大量的阿万的各种各样的分析。

28
00:02:36,425 --> 00:02:42,458
从他的技术层面，然后拿到他可能对于产业、对于产品、对于对于长远的各种各样的影响的文章。

29
00:02:42,458 --> 00:02:53,596
然后甚至都开始已经有合集了，对吧哈最近我看那个很多大家的那个群里面都在转发一个聊天记录，里面是关于阿万的十几篇你必读的文章，所以其实信息已经非常饱满了。

30
00:02:53,596 --> 00:03:02,884
那我跟雨生在商量说，我说这周日来做的这个事情的时候，雨生就说做可以，但是就是要快，要不然的话感觉好像有很多信息可能就会过时了。

31
00:03:02,884 --> 00:03:10,521
所以说这一周呢一方面在筹备这个内容，我另外呢也在想，就是我们把大家兴师动众的拉到这个地方来是吧？

32
00:03:10,521 --> 00:03:19,517
那如果我们还是讲一些相对来说比较大度户，或者比较比较比较比较常见的一些信息，我觉得就比较浪费我自己和大家的时间。

33
00:03:19,517 --> 00:03:26,306
所以说这一周在准备的过程中呢，一方面就是由pick呃帮我review了很多在技术和算法方面的细节。

34
00:03:26,306 --> 00:03:33,692
另外一方面呢我自己也在整合各方面的信息的时候，就发现了一个呃特别有趣的一个叙事的一个角度。

35
00:03:33,692 --> 00:03:46,735
所以说希望今天这个呢一方面是让大家去理解清楚阿万整个背后的脉络，但另外一方面我觉得也是让大家去看到在这一次非常精彩的一次冒险的后面的一个很美妙的一个故事。

36
00:03:46,735 --> 00:03:49,344
好，那我们那个分享今天就正式开始。

37
00:03:49,344 --> 00:03:58,040
那我们首先啊来看一看，虽然我说那个我们一般做分享的会问一下啊，还有还有没有人不知道今天要分享的这个话题的。

38
00:03:58,040 --> 00:04:01,833
但今天这个话题感觉已经已经很难去这么说了啊。

39
00:04:01,833 --> 00:04:20,440
因为那个今年过年的时候，呃，我我因为我们在上海过年没有回重庆，然后我远程给我爸妈拜拜年，然后我在视频里面我给我妈说新年快乐，然后我就听到话外音，我爸在那个画面外面啊，她不是给我给我妈说说什么，也祝儿子新年快乐，我爸在旁边吼说。

40
00:04:20,440 --> 00:04:25,060
王小云，你快问一下张涛，那个梁文峰是不是真的那么牛逼啊？

41
00:04:25,620 --> 00:04:38,513
就就今年这个dc跟阿万整个这个破圈的程度哈，就已经到了说就是像重庆这样二线城市的老头老太太们，他们都在关注这样子的话题，而且是真的是在关心就是这个背后的原理到底是什么。

42
00:04:38,513 --> 00:04:42,920
所以说呢呃我们再来看这个发生的是什么，好像也不用特别去说。

43
00:04:42,920 --> 00:04:52,060
但是呢有时候哈就是有一些事情我们还是需要在时间线上去进行一个简单的梳理啊，也来确保大家对于这个事情有一个共同的认知。

44
00:04:52,060 --> 00:04:57,460
那这个时间线呢我们可以从确认11月20号开始，就是确认12月20号。

45
00:04:57,460 --> 00:05:02,354
那个desi在自己的的官方推特上面哈，他们就发布了他们的R one light preview。

46
00:05:02,354 --> 00:05:10,118
当时发布这个呃R one的这个light preview的时候呢，说实话呃离现在的影响力我都不说1%了，可能1‱吧。

47
00:05:10,118 --> 00:05:24,801
只有极少数的人，尤其是因为那段时间11月份嘛，如果说去年欧万发布了之后，有在试图去复现欧one的同学，可能那个时候对这个阿night view相对来说有点感兴趣，甚至有人开始基于呃阿night preview再去做一些蒸馏啊。

48
00:05:24,801 --> 00:05:26,320
做一些S的一些工作。

49
00:05:26,320 --> 00:05:31,662
但是这个工作基本上是连在学术界内部都没有出圈的这样子的一个程度。

50
00:05:31,662 --> 00:05:38,210
可以这么说，这是11月20号的时候，然后到了12月26号的时候，他发了这个Dec v 3。

51
00:05:38,210 --> 00:05:42,346
那这个这个相比阿net preview呢，他的出圈程度就要多一些了。

52
00:05:42,346 --> 00:05:43,036
为什么哈？

53
00:05:43,036 --> 00:05:47,516
我等会儿会有一个例证来证明他至少在学术界里面是出圈了。

54
00:05:47,516 --> 00:05:53,376
然后第三个时间点是在1月15号的时候，他们发了他们的那个deep的app，对，deep ck app.

55
00:05:53,376 --> 00:06:01,065
然后呢，那个时候大家如果仔细看，在15号的时候，其实deep那个app里面就已经有第三条，就已经有deep think mode了。

56
00:06:01,065 --> 00:06:07,005
啊，深度思考的这个这个这个mode，但是没有人在意，就是国内也没人在意，海外也没人在意。

57
00:06:07,005 --> 00:06:12,120
呃，如果如果大家那个能回还原到15号那个语境下的话，其实可以理解啊。

58
00:06:12,120 --> 00:06:19,215
因为那个时候15号不仅是美国，还是我们我现在大家在关注的关于美国的新闻应该都只有一个是吧？

59
00:06:19,215 --> 00:06:21,690
就是那个特朗普马上要登机了是吧？

60
00:06:21,690 --> 00:06:24,000
就是大家更多的在关心这种事情。

61
00:06:24,000 --> 00:06:32,250
然后一直到20号的时候，他们正式把阿万就是一方面是paper放出来，另外一方面呢是那个模型权重整个给开源给正出来。

62
00:06:32,250 --> 00:06:39,987
然那整个的时间线，其实也就是说阿万最开始的苗头其实在去年11月份就出现了啊，也就是他其实不是在一夜之间的。

63
00:06:39,987 --> 00:06:47,763
然后这过程中还有很多几个关键的东西，包括为什么要说V 3，这个也是我们今天这个分享后面会探讨一个很主力的一个话题。

64
00:06:47,763 --> 00:06:53,777
然后呢，我想我再给大家看一个特别有意思啊，就是这个是在那个谷上面就是搜索deep stick这个关键词。

65
00:06:53,777 --> 00:07:02,140
那么你也可以看到，其实它整个的启示是在20号1月20号之后，就是阿万的那个发布之后，慢慢在学术界开始有一些小分面在讨论了。

66
00:07:02,140 --> 00:07:13,878
然后呢在那个20号到24 27号的时候逐渐升温，然后直到27号把那个英伟达以及移众美国的这个AI概念股直接给砸下一个巨坑。

67
00:07:13,878 --> 00:07:16,616
然后这个搜索量直接达到了顶峰。

68
00:07:16,616 --> 00:07:29,920
而且并且在持续了一周之后，你看他它虽然后面跌回去了啊，谷的那个搜索指数是一个呃就是均医化之后的一个就是从0%到百分之百的这样一个比比例值。

69
00:07:29,920 --> 00:07:39,995
也如说虽然说你看接下来的从那个一周之后到现在，整个的那个流量是有所回回调，但相比在20号之前来说，20号线前基本上是贴到0的。

70
00:07:39,995 --> 00:07:45,289
但你看现在基本上也是回到20%，也就是说这个热量并没有掉下去。

71
00:07:45,289 --> 00:07:56,560
然后下面给大家讲一个特别有有有意思的话题，不知道有没有人能猜得到哈，就大家猜一猜在美国我们如果按照行政区域划分，大家猜哪一个地方最关注deep sick。

72
00:07:57,500 --> 00:08:00,107
哎呦，好，那女生直接终结了这个比赛。

73
00:08:00,107 --> 00:08:03,930
我本来想大家本来想大家猜猜啊加州啊什么之类的。

74
00:08:03,930 --> 00:08:08,449
对啊对对，特别我还用了行政区划这样的词啊，就为什么不用周？

75
00:08:08,449 --> 00:08:12,446
对我当时在看这个这个这个图纸，我也觉得非常有意思。

76
00:08:12,446 --> 00:08:19,572
就我本来以为是加州嘛，因为这个AI嘛很多关注，结果发现最高的居然是是是是dc特区啊，是华盛顿。

77
00:08:19,572 --> 00:08:27,220
我我都可以想象哈，就是27号砸下了个深坑之后，华盛顿的一众政客在上疯狂搜索啊，基到底是个啥呀？

78
00:08:27,220 --> 00:08:35,823
对，后面几个排名还比较正常啊，就是像加州啊，像那个华盛顿州啊，这些都是传统的这个埃踢公司搞A呀研究的人在在的地方。

79
00:08:35,823 --> 00:08:41,284
哎，对，但是第一就是热度最高的居然是在这个D C，这个也是一个非常好笑的啊。

80
00:08:41,284 --> 00:08:46,911
好，那我们前面讲的是这个就是呃主动方，就是发布工作的这一方的这个这个反应。

81
00:08:46,911 --> 00:08:53,200
那我们现在来看一看，就在美国社会哈他的各种各样的这个精英K O L对这个事情的反馈。

82
00:08:53,200 --> 00:09:05,785
那我大家应该有记得我前面有提到，我说在12月20号的时候，就是那个呃他们发12月26号他们发布V 3的时候，相比前面发阿night preview，我说他至少在学术这次破出来了。

83
00:09:05,785 --> 00:09:06,805
为什么这么说？

84
00:09:06,805 --> 00:09:13,268
大家可以看这一页右边的这张图，这是ancapacity啊，ancapacity就不需要我再介绍他是谁了，对不对？

85
00:09:13,268 --> 00:09:21,818
在那一天ancapacity发了一条非常长的推特，然后在那介绍V三这个工作，并且说啊他说这个真的是一个very nice and detailed tag report。

86
00:09:21,818 --> 00:09:24,450
我正在读啊，他他后面还发了一些感想。

87
00:09:24,450 --> 00:09:31,686
我当时在研究他这条图的时候，还发现了另外一个特别有价值的内容，会在我们后面的那个时里面放出来。

88
00:09:31,686 --> 00:09:38,759
但至少证明在12月26号V 3发布的时候，这个工作其实已经获得了美国的主流的学术圈的认可。

89
00:09:38,759 --> 00:09:44,186
但那个时候呢可能大家还没有意识到V 3的更重要的另外一个价值又是什么。

90
00:09:44,186 --> 00:09:48,298
好，我们再回到那个春节期间的那个那个炸街的那个过程哈。

91
00:09:48,298 --> 00:09:52,739
你看一开始我第一次注意到那个美国那边的舆论变了，是什么啊？

92
00:09:52,739 --> 00:09:59,983
因为雨神我们都在在同同时在很多群里面，女生应该也看到，就是当时我特别兴奋，我接了那个mark an的那个推。

93
00:09:59,983 --> 00:10:04,926
因为mark an大家知道在通常意义上来说，它其实是一个以前的反华的先锋军。

94
00:10:04,926 --> 00:10:11,352
他对于中国的态度一直是比较aggressive，而且有时候发东西都是一些比较轻蔑的那种那种态度。

95
00:10:11,352 --> 00:10:18,601
但是我当时我印象最深的就是他在23号的时候开始发，哇，这个是个什么东西，他太太炸了什么之类的。

96
00:10:18,601 --> 00:10:26,840
然后在24号的时候，他发了他发了这一条，就他前面发的都是说呃这个这个阿旺也太好了吧，然后他甚至还要加批注。

97
00:10:26,840 --> 00:10:34,093
大家请注意，我说他好不是代表我高，不是代表我我我我感到高兴，我是觉得很危险，就他还要去批注。

98
00:10:34,093 --> 00:10:36,746
但到了第二天，他的语气就完全变了。

99
00:10:36,746 --> 00:10:43,115
大家可以明显看得出来，这条腿应该没有任何的negative的这个这个情绪在里面了，对不对？

100
00:10:43,115 --> 00:10:46,830
这是一个非常正面的这样子的一个一个一个情绪。

101
00:10:46,830 --> 00:10:51,429
然后呢到了28号，赛文奥特曼也被逼的出来这个发言是吧？

102
00:10:51,429 --> 00:10:58,860
虽然说的那个别别别别扭扭的啊啊，还要假装一下说，哎呀，其实我是想开源的啊，组组织上不允许是吧？

103
00:10:58,860 --> 00:11:02,323
就说的比较这个，然后包括像那个呃杨丽坤是吧？

104
00:11:02,323 --> 00:11:13,407
哎，杨丽坤等这些都是属于AI g的这个顶级cool l了也出来首先承认了阿万的这个工作的impact和质量啊，但是呢这个杨立坤要把这个话往开源上面引是吧？

105
00:11:13,407 --> 00:11:16,351
就不是中国的胜利啊，是这个开源的胜利。

106
00:11:16,351 --> 00:11:21,719
对，但是无论如何就是一个工作得到了美国AI界最顶流的这个领袖的认可。

107
00:11:21,719 --> 00:11:25,356
不管是对于质量的认可，还是对于这个事情的认可。

108
00:11:25,356 --> 00:11:28,820
那我们认为说这个事情它的impact已经在这里了。

109
00:11:28,820 --> 00:11:34,188
至于说这个impact的是好是坏，原因是什么，那是我们接下来要去探讨的话题。

110
00:11:34,188 --> 00:11:50,206
但这个impact本身是毋庸置疑的啊，当然的就是大家知道这个舆论环境呢，包括获取信息的的这个能力差距啊，我我印象特别深刻就是呃大家可以看这些都是1月24号28号的那个推了。

111
00:11:50,206 --> 00:12:06,432
到了2月23号的时候啊，还有很多的这个就是所谓的反贼类型的，呃，还在说啊这个工作就是deep seeke请的水军各种炒作，其实根本主流那个圈子就没有关注的，但是这个是事实摆在面前是吧？

112
00:12:06,432 --> 00:12:17,517
这个不用去辩这个啊，然后完了之后就是最厉害的1月27号那一天啊，那个大家都炒莓股哈，应该都都对这一天记忆犹新是吧？

113
00:12:17,517 --> 00:12:25,112
左边从上到下是nvideo dia，然后那个tsm c还有美光啊，你看这个都是属于一下砸下一个天根。

114
00:12:25,112 --> 00:12:37,934
右边就是那个从上到下是那个中芯国际360和那个金山云啊，就就本来那个这些都都是那个唱衰唱衰中国，结果感觉突然这一天就变成了这个东升东升西落啊。

115
00:12:37,934 --> 00:12:42,002
所以他对于那个真实世界的这个影响也是毋庸置疑的。

116
00:12:42,002 --> 00:12:45,540
就不管是AI领袖还是这个真实世界的这个impact。

117
00:12:45,540 --> 00:13:07,837
然后呢那个呃后面哈比如说我们在那种类似的监测软件上面，我们可以看到左边这张图呢是DAU紫色呢是那个呃chat gb t然后下面那个突然异军突起的那个，大家就会看到其他家哈，不管说我们觉得chat gb t后面还有很多跟随的，像cloud呀，像那个perplexity啊呃Jina我都不好意思都不好意思说他。

118
00:13:07,837 --> 00:13:16,060
对，那这两家不都说跟随，但是你要看在他占千的gp t的比例一直是非常恒定，而且是一个很小的一个值。

119
00:13:16,060 --> 00:13:25,414
但是在一月最后几天发生了极大的这个变化，就是deep sike一下起来，应该我目测20%的比例应该是有了吧，对吧？

120
00:13:25,414 --> 00:13:31,261
而且你看右边那张图是那个新增这个当lo子这个当lo打穿了之后也还那个。

121
00:13:31,261 --> 00:13:35,939
然后这个数据是这个数据好像应该是是mark Anson发的吧，忘了。

122
00:13:35,939 --> 00:13:40,226
然后他我我我我截了个图的时候已经比较比较早了。

123
00:13:40,226 --> 00:13:56,898
我们昨天我们又看了一下最新的那个套这个这个左边那张图还在往上走，然后右边这张图的那个下载量虽然有所回落，但是也也还是比开级P D高啊，这个趋势到目前还在还在维持啊，至少在我们观察看的。

124
00:13:56,898 --> 00:14:09,870
所以说不管是从业界领袖，然后对于这个股票市场，还是说真实的这个用户的用用用脚投票的这个选择，都证明了这个impact是真实存在，而且是真的有用户价值的。

125
00:14:09,870 --> 00:14:15,931
啊，那么这也是在过去的这呃接近半个月的时间里面啊，它发生的事情是什么？

126
00:14:15,931 --> 00:14:25,106
啊，那接下来回到说我们为什么要组织今天这个学习，以及呃我为什么要去做这个分享的一个一个很重要的一个事情。

127
00:14:25,106 --> 00:14:31,762
哎，呃大家稍等一下，我屏幕上有个那个叉，我要把它擦掉O啊为什么要去做这个分享？

128
00:14:31,762 --> 00:14:39,035
其实一个很很很简单的事情就是我我从1月22号23号开始开始关注这个事情。

129
00:14:39,035 --> 00:14:44,538
然后就频繁的中美各方面看了很多很多的言论，包括圈内的、圈外的。

130
00:14:44,538 --> 00:14:50,042
然后你就会发现啊就是呃随着随着这个就是大家这个呃怎么说呢？

131
00:14:50,042 --> 00:15:00,230
随着它逐渐破圈，逐渐有非圈内的人士开始出现，你就会现大家对于这个事情的归因会特别喜欢，把它归因到一个特别简单的上面。

132
00:15:00,230 --> 00:15:03,329
比如说要么就是啊叫中国人工便宜是吧？

133
00:15:03,329 --> 00:15:09,529
这个是一个经典的这个中国用便宜的人工哎把美国的顶尖科技给成本打下来了。

134
00:15:09,529 --> 00:15:16,275
有这样子的说法啊，也有那种说这个是中国的这个抄袭是吧哈，就一个东西抄了就就行了。

135
00:15:16,275 --> 00:15:27,580
那当然还有另外一面的叙事是吧哈就是说这个这个这个是那个呃什么一个很不出名的小团队啊，就突然搞出来的这个全球顶尖式的这个科技创新。

136
00:15:27,580 --> 00:15:33,661
但是无论怎么样哈，你会发现大家对这个事情的归因，它特别的表面，而且特别的外向。

137
00:15:33,661 --> 00:15:44,087
都试图在整个的公司外部或者是说脱离开产品，脱离开这个技术本身，去把它归因到一些呃很很我觉得它的相关性没有那么高的一些事情上面。

138
00:15:44,087 --> 00:15:49,821
那我觉得当你面对一个那么重大的事件的时候，如果去做这么简单的归因的话。

139
00:15:49,821 --> 00:15:54,860
哎，雨生他这个有个会议人数一达100人，新新人数暂时无法加入这个。

140
00:15:55,380 --> 00:16:06,747
嗯，好，我我我得把这个这个点开啊，我那我照顾线上同学哈，我们先往前面走哈，后面没进来的同学我们再说。

141
00:16:06,747 --> 00:16:24,197
那我觉得最好的哈就是当一个那么大的impact的事件，在我们的人人一辈子哈就不到100年是吧哈就是整个这个过程当中发生了那么重要的一个事情的时候，我觉得最好的方式不是简单的把它归因，然后就放到自己的这个大脑记忆里面。

142
00:16:24,197 --> 00:16:32,221
而是去学习它，去理解它，搞清楚那么对于产对于世界产生这么大的一个impact的东西，它到底是怎么发生的啊，原因到底是什么？

143
00:16:32,221 --> 00:16:37,588
我觉得这个东西很重要，所以这也是准备这次这个分享的一个很重要的一个一个原因。

144
00:16:37,588 --> 00:16:49,812
那么要解决这个问题呢，我们第一个哈对于绝大部分的这个听众来说，因为我们今天是一个大家知我是做产品的，我不是专业搞搞算法搞工程的啊，那我们大部分的这个听众可能也是这样子的背景。

145
00:16:49,812 --> 00:16:51,900
那我们要解决的第一个问题就是。

146
00:16:51,900 --> 00:16:53,426
什么是推理模型啊？

147
00:16:53,426 --> 00:16:56,290
我们已经有那个呃大圆模型了是吧？

148
00:16:56,290 --> 00:16:59,153
啊，那我们为什么要需要推理模型啊？

149
00:16:59,153 --> 00:17:05,833
那首先为大家来做一个测试哈，比如说那个我今天就找现场，我熟一点的吧啊叫海波。

150
00:17:05,833 --> 00:17:08,695
哎，对你现在也看得到屏幕是不是啊？

151
00:17:08,695 --> 00:17:18,240
哎呃我不知道大家知不知道哈，就是人脑有一个非常特殊的一个能力，就是识别数字啊，不是识别数字吧，就是叫识别数量。

152
00:17:18,240 --> 00:17:32,937
但是通常一个正常人能一眼，就是你看到一个东西，你比如你我等会儿会切换这个图，然后你立马就要告诉我多少颗黄球，一秒钟之内，通常人只能识别6和6个之内的超流。

153
00:17:32,937 --> 00:17:36,042
你这个一看就就知道是五个，是不是？

154
00:17:36,042 --> 00:17:38,112
哦，哦这这个也有那个了。

155
00:17:38,112 --> 00:17:42,252
呃，行，等会儿给韩授说哦，那个点一下就行了是吧？

156
00:17:42,252 --> 00:17:44,757
啊，是不是点一下就行了啊？

157
00:17:44,757 --> 00:17:51,192
哎啊ok ok好，那我等会会切的时候，你一秒钟就告诉我有几个小号吧。

158
00:17:51,192 --> 00:18:10,245
啊啊我我切了啊，321切啊，切好没完再来啊，切九呃，停留停停再来呃，再来再来啊。

159
00:18:10,245 --> 00:18:16,198
行，哎，所以说其实就是其实大家就知道一个一个非常有意思的一个事情是什么啊？

160
00:18:16,198 --> 00:18:24,253
就是我们人对于那个数量的那个思维，大家可以回去测各种各样的东西，包括矿泉水瓶、苹果，还有很多很多东西。

161
00:18:24,253 --> 00:18:37,440
你会发现我们人在就是长达几千万年上帝的进化当中，我们学到的一个非常神奇的东西就是数数这个东西我们不需要真的去数，在一定的数量范围之内啊，我就可以直觉说出来。

162
00:18:37,440 --> 00:18:46,945
而语言模型大语言模型有一个当然哈我这个类比可能不是那么恰当，但是它仍然有一个同样的一个特性是什么呢？

163
00:18:46,945 --> 00:18:52,490
就是他一把说的时候啊，就我们说一个答案，然后一把说通常会说错。

164
00:18:52,490 --> 00:18:58,035
对对，就是当时这一篇那个很经典的这个接生谓的这个co t吧是吧？

165
00:18:58,035 --> 00:19:05,560
切他提出来的，它里面有个很重要的一个思想，就是说模型需要前置的更多的token让他来思考。

166
00:19:05,560 --> 00:19:08,580
哎，那从co由T的角度大家都能理解。

167
00:19:08,580 --> 00:19:15,626
然后那个呃pick我们在read这个过程当中，pick给我说了一个呃我觉得直击本质的这个话。

168
00:19:15,626 --> 00:19:32,679
就大家想语言模型本质是说我们去激活一个很大的这个神经网络矩阵，那你只用一个token进去的时候，它能够关联到的或者能够激活到的整个矩阵里面的方向是有限的那当你有更多的头啃了之后，你才能更多。

169
00:19:32,679 --> 00:19:36,857
那大家知道信息量，这个信息量它本身是跟这个是相关的。

170
00:19:36,857 --> 00:19:46,084
所以你有越多的token的时候，他可能才能够虽然我们不知道他到底激活哪些知识哈，他可能才能够有足够的信息去做出这个决策。

171
00:19:46,084 --> 00:19:54,789
所以说呢因为模型需要更多的Coken来think，所以说我们在归推拉出了说我们可能需要一个模型叫做reasoning model，叫做推理模型。

172
00:19:54,789 --> 00:19:56,182
什么叫推理模型啊？

173
00:19:56,182 --> 00:19:59,489
比如说我们觉得一把说的模型是什么样子的。

174
00:19:59,489 --> 00:20:03,320
就我问他一个问题，从望京西到西直门坐地铁要几站？

175
00:20:03,440 --> 00:20:09,226
一个一把数的模型，像左边这样，它就直接说就站啊，忘前去，汪当就直接吐出来了。

176
00:20:09,226 --> 00:20:12,382
而一个reasoning model他会怎么回答这个问题呢？

177
00:20:12,382 --> 00:20:23,079
他他他他会在脑内幻想啊，要知道这个要挤站，首先要知道这种换乘换乘路线啊，第一种路线怎么样，第二种路线怎么样，让你综合起来看，我选择这样。

178
00:20:23,079 --> 00:20:25,007
对，这个就叫这个reasoning model。

179
00:20:25,007 --> 00:20:33,600
就是它除了吐出这终答案以外，它会试图在中间去把它的这个所谓的这个打引号的思维过程给大家给这个展示出来。

180
00:20:33,600 --> 00:20:42,338
但如果说你现在用千芯剂已经用了两年多了，你可能听到看到这样子的一个东西，你会会不会很直接的说，这不就co t吗？

181
00:20:42,338 --> 00:20:42,687
对吧？

182
00:20:42,687 --> 00:20:45,833
这就是思维链啊，这有个什么新新的东西呢？

183
00:20:45,833 --> 00:20:54,222
还需要去搞个reasoning model嘛，我直接写个co t是吧哈让这个模型呃去按照我的这个想法，呃，一步一步的这样子去去设。

184
00:20:54,222 --> 00:20:58,241
比如说前面这个我就说呃万年西到系什门，究题要几站？

185
00:20:58,241 --> 00:21:04,183
呃，请先列出可能的换乘路线，再计算各路线的换乘站，最后综合得出一个最佳答答。

186
00:21:04,183 --> 00:21:10,426
当然如果说你愿意为你的每一个问题都写如此详细的cot，我觉得三号也是可以的啊。

187
00:21:10,426 --> 00:21:12,603
对，但是呢有个问题是什么呢？

188
00:21:12,603 --> 00:21:24,756
就是我们来看一看去年震惊整个业界哈，就是当时那个ChatGPT的o one o系列模型发布的时候，他把那个整个大家打榜的那个奔驰mark刷到了一个什么样子的程度。

189
00:21:24,756 --> 00:21:28,565
就是在那个之前，比如说那个呃这是三个方向的哈。

190
00:21:28,565 --> 00:21:35,640
比如说第一个是那个数学方向，第二个是写代码方向，第三个是那个PhD level的这个科学问题方向。

191
00:21:35,640 --> 00:21:44,062
大家可以看这这三个领域里面，在数学领域直接就从他上一代的gbt 4O拔地而起，从13分拉到了56分和83分。

192
00:21:44,062 --> 00:21:54,674
在写代码方面直接从11分拉到了89分，都快把那个榜给打爆了啊，最后那个Ph D level那个确实太难了，他提升可能没有前面那么大，但也非常恐怖了。

193
00:21:54,674 --> 00:22:00,401
说实话就是如果你经常看paper，你就会发现你把那个奔驰mark刷一两个点都能翻到paper。

194
00:22:00,401 --> 00:22:05,960
人家这个78到56已经刷了不知道多少了，只是说相比前面没那么夸张。

195
00:22:05,960 --> 00:22:09,154
但但是Ph D level那个最最厉害的是什么？

196
00:22:09,154 --> 00:22:29,721
大家看最右边绿色那条线，那个是人类专家，是真正的Ph D就那个是o one已经超过了真正的Ph D那也就是说是我们前面说那个reasoning model，本质上就是让模型自己在构建co t模型，自己再把前面cot段帮你演绎出来，你当然可以自己搞，但问题是什么呢？

197
00:22:29,721 --> 00:22:34,405
问题就是我们人真的要去搞C T你搞得出来这些C T吗？

198
00:22:34,405 --> 00:22:46,255
比如说这两个题，就是我从前面的这个呃第一个AME2024的这个分期mark和后面的那个呃gpq a呃PhD level的那个分期mark里面找出来这两道题啊。

199
00:22:46,255 --> 00:22:56,163
我我我当然知道，如果你的那个高考数学还没有完，或者是那个你真的是一个物理方面的PhD可能你真的知道这个co怎么写。

200
00:22:56,163 --> 00:23:02,380
但是绝大多数人呢，是不是我们人没有办法对每一个问题都能够把他的这个。

201
00:23:02,380 --> 00:23:06,311
Step by step的这个或者是说这个思维模式能够弄得出来。

202
00:23:06,311 --> 00:23:11,136
所以说我们需要一个reasoning model来帮助我们去处理一些特定问题。

203
00:23:11,136 --> 00:23:21,680
方向的时候，比如说啊典型的说哪些场景适合用推理模型，像那些谜题是吧，我们经常什么给一个二战时期的那个密码电文，让你把它翻译出来。

204
00:23:21,680 --> 00:23:36,870
哎，或者是一个数学证明题，或者是一个复杂的决策问题，或者最后答案是一个open open ended的一个开放式的一个答案，或者是说有些问题就是要一步一步的才可能得到最后的结果，要显示的把这个思考给放出来。

205
00:23:36,870 --> 00:23:43,377
那么这个时候就适合用reasonmodel啊，它来帮你把前面的那个呃cot的部分就是来帮你解决。

206
00:23:43,377 --> 00:23:45,778
但是它不它不适用什么场景呢？

207
00:23:45,778 --> 00:23:48,735
一个就像一加一等于2这种太简单了。

208
00:23:48,735 --> 00:23:52,799
就你用cot呃一方面用model啊，一方面是呃浪费token啊很贵。

209
00:23:52,799 --> 00:24:05,732
另外一方面呢有时候模型想的太多了之后啊，会把一个简单的答案给搞错啊，还有一个就是一些知识性的回答，比如中国的首都是哪里啊，他这个就就直接就就就打北京。

210
00:24:05,732 --> 00:24:08,503
这种你也没有必要去用这种really model。

211
00:24:08,503 --> 00:24:11,460
所以说它其实really model它有适用的场景。

212
00:24:11,460 --> 00:24:15,364
那为什么他会对于我们这个行业如此的重要呢？

213
00:24:15,364 --> 00:24:16,926
这有两方面的原因。

214
00:24:16,926 --> 00:24:24,344
一外方面是大家看到左边这个里面啊有很多的什么编代，就是什么写代码呀、数学呀、Ph D呀。

215
00:24:24,344 --> 00:24:37,620
在这些领域的能力突破，会使得现在可能只是陪伴大家作为chat bot的这样一个单元模型的应用，进入到真的能够让一个国家的那个科技研究加速的这个领域里面去。

216
00:24:37,620 --> 00:24:44,604
所以说这也是就是所有搞A I的那个大模型厂商，大家都要追求的A G I甚至A S I是吧？

217
00:24:44,604 --> 00:24:46,626
就比人更聪明的这个领域。

218
00:24:46,626 --> 00:24:58,574
另外一个方面呢就是至少目前从阿one的这个结果，包括之前大家玩o one的这个过程中，我们发现虽然说训练reasoning model是在解决数学物理写代码方面的问题。

219
00:24:58,574 --> 00:25:13,305
但我们发现一个模型通过学那样的reasoning的过程了之后，我们发现他在解决一些更更general的场景的时候，包括写作，包括对话这些场景的时候，我们发现它也变得更有逻辑，更有这个思维的能力了。

220
00:25:13,305 --> 00:25:21,958
所以这也是为什么在reasonmodel这个事情上，基本上去年下半年开始就成为了大家都想去攻克去解决的这样的一个方向。

221
00:25:21,958 --> 00:25:23,901
哎，好，那所以说我们需要它。

222
00:25:23,901 --> 00:25:27,080
那问题就来到了我们到底该怎么复现o one？

223
00:25:27,080 --> 00:25:28,316
那怎么复现欧one？

224
00:25:28,316 --> 00:25:30,612
我们首先要去看欧one对不对啊？

225
00:25:30,612 --> 00:25:36,440
但我们今天没有那么时间去看欧one哈，但只跟大家讲一个特别有趣的一个事情。

226
00:25:36,440 --> 00:25:51,451
右下角是欧万在发布那一天，他把他的那个核心的contributor，他叫呃foundational contributor啊，就是说下面还有很多的contributor，这一组人叫foundational contributor是最核心的，他把这些人公布出来了。

227
00:25:51,451 --> 00:26:09,164
左上角是OpenAI在彻底就是go silent之前，就OpenAI在二这那个那那个let's verify step by step应该是二三年的时候，就是他们彻底go sil之前发的最后一篇paper那个之后他们就没有再发那种正式的那种research paper那种发面的东西了。

228
00:26:09,164 --> 00:26:13,102
这是他们发的最后一篇，发了那篇他们就没发了。

229
00:26:13,102 --> 00:26:16,056
然后一年之后他们搞了个o one出来。

230
00:26:16,056 --> 00:26:27,280
所以说呢，而而那一篇let's verify step by step讲的就是说通过把一个问题一步一步的拆解，对每一步进行打分，然后来训来强化学习，训练一个模型。

231
00:26:27,280 --> 00:26:38,765
所以说有当时就有很多人在欧文发布之后，去回看open朋A埃的这个工作，发现他们去年做的最后公开的工作就这个，然后就再也没公开工作了。

232
00:26:38,765 --> 00:26:43,632
所以说有很多人都觉得let's verify step by step就是o one复现的关键。

233
00:26:43,632 --> 00:26:52,782
并且他们当时还公布了一个p m 800K的数据集，这个数据集的格式就是在这个截图上下面大家看到的两个格式。

234
00:26:52,782 --> 00:27:03,012
比如说就是他们他下面说了一道说了一道题，然后呢这个题他给出了每一步的reasoning过程，并且有每一步reasoning过程的打分。

235
00:27:03,012 --> 00:27:10,701
就是说呃positive neutral或者是negative就是open a公布了一个这个p m 800K的这个一个数据集啊。

236
00:27:10,701 --> 00:27:27,900
那大家想一想啊，如果你是一个在o one发布之后，开始去研究o one的一个researcher，你一看他们最近的一篇你能看到的paper在讲这个哦，一步一步的强化学习，对这个整个的这个解解解决问题的每一步进行打分。

237
00:27:27,900 --> 00:27:44,234
嗯，感觉应该这个方向在看到这个p m 800K这个这个数据集的时候，你就很难不容易想到说o one应该是用了这么一个呃这个pm其实就是那个process reward model啊，就是过程激励模型，你又很难不往这个方向去想。

238
00:27:44,234 --> 00:27:54,420
所以说如果你在谷上面去搜如何复现o one，我就随便搜了一下，然后点了那个排行最高的这篇文章，是去年12月30号的文章。

239
00:27:54,420 --> 00:28:04,739
然后呢，在这个文章里面他有提到说欧文发布之后，国内陆续发布了很多内欧湾的模型啊，他这个地方提到的阿万还不是我们现在的阿万哈。

240
00:28:04,739 --> 00:28:12,211
因为去年12月份的时候，那个时候大家能接触到是那个阿one night preview，呃，包括那个Kim的math相关的东西。

241
00:28:12,211 --> 00:28:17,193
然后他说基本上分成两个派系啊，一个叫数搜索派啊，一个叫真馏派。

242
00:28:17,193 --> 00:28:28,580
速搜索派比较像刚刚那个open I的那个verify step step的那样子，一个一个路线的一个细分啊，真馏派呢就是说用那个已经有的那个模型，比如说呃欧二这些去做。

243
00:28:28,580 --> 00:28:36,084
大家发现这个里面根本就没有提到最近大家在各种文章当当见到的那个阿万的什么pure R L是吧？

244
00:28:36,084 --> 00:28:39,196
纯强化学习派根本就没有提到这个方向。

245
00:28:39,196 --> 00:28:43,223
因为当时整个业界大家都觉得open应该就是这样做的。

246
00:28:43,223 --> 00:28:53,656
所以所以说当时我我知道的哈就是在硅谷那边和在国内有很多厂商都开始来筹备去准备那个呃类似于像p m 800K这样的数据集了啊。

247
00:28:53,656 --> 00:29:06,377
呃呃这样说人闲话可能不太好啊，但我但我还但我还是还是想说哈，我当时有特别阴暗的一个想法啊，我就觉得为什么这次事件里面Alexander王是吧scale X U跳脚跳的这么这么急。

248
00:29:06,377 --> 00:29:12,645
我一直觉得一个很重要的原因就是因为他可能接了很多那个那个prm数据的标注订单。

249
00:29:12,645 --> 00:29:15,780
然后然后现在好像突然发现没啥没啥用了。

250
00:29:16,500 --> 00:29:25,557
对嗯，所以说你看当时的业界就是这个样子的啊，就是而且但虽然这个就是中文啊啊，不代表只有我们中国人这么搞啊。

251
00:29:25,557 --> 00:29:35,354
就是你去看微博里面，其实呃除了那个cloud，除了跟open I以外，其实很多其他的团队可能也是在往这些方向做啊，做做做c ts啊是吧？

252
00:29:35,354 --> 00:29:40,344
蒙德卡拉苏搜索啊这些基本上都在都都在在搞这些类型的方向。

253
00:29:40,344 --> 00:29:47,670
但是这个就是我们今天故事第一个高潮啊，也是我在就是在这两个星期里面让我爽的第一次。

254
00:29:47,670 --> 00:29:59,359
就是在所有的都在走向一个至少在现在看来是暂时错误的方向的时候，其实有两个团队啊，他们同时在进行一场非常精彩绝伦的探索之旅。

255
00:29:59,359 --> 00:30:05,001
有两个团队，而有幸人这两个团都是中国团队，一个是Steve sike，一个是pimi。

256
00:30:05,001 --> 00:30:11,047
啊，对，那我们来先来看一看为什么我说这是一个精彩绝伦的探索之旅啊。

257
00:30:11,047 --> 00:30:17,790
呃pimi呢他们在那个呃就是在阿万的那个发布的左右呢，也发布了他们的k米KK1.5。

258
00:30:17,790 --> 00:30:27,317
同时当然他们不是开源哈，但他们写了一篇很详尽的这个呃tech report来介绍他们训练那个呃K1.5的这个模型背后的事情。

259
00:30:27,317 --> 00:30:33,363
但我说实话，从用文本身的阅读体验来说，K1.5的阅读体验相对是比较差的。

260
00:30:33,363 --> 00:30:37,577
如果你去读阿万和V 3的时候，阿万和V 3就极其精彩。

261
00:30:37,577 --> 00:30:42,523
我们等会儿会会会有一些那个呃读一些阿万和V 3一些片段啊。

262
00:30:42,523 --> 00:30:52,520
K1.5呢嗯里面充斥着大量的工程细节，我觉得对于如果你真的是要想去复现那个工作方式的人来说，K1.5是更有价值的。

263
00:30:52,520 --> 00:31:09,940
因为它里面附了很多的工程细节，细节到我觉得真的就是手把手教你实现的那种感觉啊，但是他的整个阅读体验其实很差，但是呢我在那个推特上找到了他们的一个员工哎，写的这一篇就是k米1.5背后的思考过程这篇文章。

264
00:31:09,940 --> 00:31:15,538
这篇文章的文笔真的太棒了，就是读得人心许，就是心潮澎湃。

265
00:31:15,538 --> 00:31:18,673
但所以说我不得不带大家读一遍。

266
00:31:18,673 --> 00:31:21,584
当然哈我们会用啊有中文文吗？

267
00:31:21,584 --> 00:31:22,928
知读就哦是吗？

268
00:31:22,928 --> 00:31:31,574
对，哦啊啊啊没什么没什么没什么，因为我也不是真的要大家赌，哎，我就快速对大家快速大家这个过过一下啊。

269
00:31:31,574 --> 00:31:37,150
对对对啊，对，因为他这个文笔实在太好了，所以我当时读的难以难以自拔啊。

270
00:31:37,150 --> 00:31:48,301
对对，首先啊就是他说那个9月12号欧文发布了是吧，然后呢就举举世震惊啊，举世震惊，然后呢那个发现那个long co t是吧啊就是呃真的真的很有效。

271
00:31:48,301 --> 00:31:56,949
然后他就来思考啊，就是说呃那个呃我们一定要搞这个，让让co t必须要搞，不搞的话就就肯定要肯定要落后。

272
00:31:56,949 --> 00:32:01,891
那我该如何在这个open I那边去去找去找到那个找到灵感呢？

273
00:32:01,891 --> 00:32:04,264
是吧哈他在讲他整个的过程。

274
00:32:04,264 --> 00:32:15,336
好，然后第一个亮点来了，他说他在整个去研究o one的过程当中呢，他发现有两个特别重要的video open的video放出来啊，一个是这个一个是这个。

275
00:32:15,336 --> 00:32:16,720
然后他说什么呢？

276
00:32:16,720 --> 00:32:30,160
他说我看了这两个video很多很多次，因为他发现这两个video并不是九月份的时候的分享，也有那两个那两个video是就是那个呃nom和这个hum我， 不知道怎么读啊。

277
00:32:30,160 --> 00:32:40,186
他们很早也不是很早前吧，几个月前做的分享，但一直没放出来，一直等到欧万发布的时候才把这两个视频放出来。

278
00:32:40,186 --> 00:32:47,672
所以他就觉得哎就虽然这两个视频看起来都跟欧万的训练没关系，但为什么要挑这个时间放出来？

279
00:32:47,672 --> 00:32:48,723
一定有点关系。

280
00:32:48,723 --> 00:32:53,975
哇，这是我自我创足的时候，我说我靠这这这这这想法真牛逼啊，是不是哈？

281
00:32:53,975 --> 00:32:56,602
然后呢他就去研仔细看这两个视频。

282
00:32:56,602 --> 00:33:01,504
然后完了之后呢，他就发现了第一个nom那个视频里面的那个这一页。

283
00:33:01,504 --> 00:33:13,060
这个sli就是在讲那个呃呃就是在那个当做阿尔法go的时候是吧哈那个阿尔法go大家知道当时击败李世石之后，他们又训练了更强大的阿尔法，叫阿尔法go zero。

284
00:33:13,060 --> 00:33:16,821
那个zero就是一个纯R L的这个这个版本。

285
00:33:16,821 --> 00:33:21,467
他就说这一页slides强调了那个test time search啊，就是的。

286
00:33:21,467 --> 00:33:37,840
然后呢，很多人都以为norm讲这个是为了讲那个阿尔法go的mc ts就是做那个蒙斯卡书的那个搜索，就是同时发展很多条路径，然后看去继续打分，然后去找出一个好的一个一个路径。

287
00:33:37,840 --> 00:33:55,804
但是他有一个非常不同于大众的判断，就大家都以为他他觉得那个nom放这一页是在强调M C T S，但他觉得nom是在强调S本身就是在强调search，而不是在强调蒙特卡拉数搜索，他是在强调搜索。

288
00:33:55,804 --> 00:34:01,867
所以说呢他他他讲的他讲到的第一个idea就从那个视频里面得到。

289
00:34:01,867 --> 00:34:15,670
就是我们要让模型自己学会去探索不同的方向啊，自己去自己去search，去找到这个路径答案，而而不是通过什么，而不是通过我们人为去限制他的这个思考。

290
00:34:15,670 --> 00:34:22,359
比如说包括他说那个呃让他想到了那个Richard的那个特别出名的那那一篇是吧？

291
00:34:22,359 --> 00:34:23,574
Bitlisten son对吧？

292
00:34:23,574 --> 00:34:26,007
啊，就是特别出名的那一篇啊。

293
00:34:26,007 --> 00:34:31,481
然后他这个很多时候跟人家授说模型要自己烧，而不要我教他烧。

294
00:34:31,481 --> 00:34:38,237
然后呢另外一篇就下面那个费用，这个don't teach啊，in就说不要教他，要鼓励他，什么意思呢？

295
00:34:38,237 --> 00:34:44,199
就是他们发现啊就是这个这个大家不用特别去看那个下面这个图是什么意思啊？

296
00:34:44,199 --> 00:34:52,795
他基本上讲意思就是说他们在很多的一些序列当中会发现模型或者说整个这个framework它的structure越少就less structure。

297
00:34:52,795 --> 00:34:58,057
那么随着你未来你给他更多的computer te计算资源，这个模型的上限会更高。

298
00:34:58,057 --> 00:35:04,371
如果你早期的时候给了过多的structure，现在比较死，那么它最后的表现其实就没那么好。

299
00:35:04,371 --> 00:35:07,880
然后他又说为什么这个同学要特别强调这一页？

300
00:35:07,880 --> 00:35:09,284
Structure what is structure?

301
00:35:09,284 --> 00:35:11,566
我当时读这篇的时为什么爽呢？

302
00:35:11,566 --> 00:35:16,656
就是因为我感觉是在看看这个哥们儿，就听你这个哥们儿的老泪对话。

303
00:35:16,656 --> 00:35:18,412
哎，对，structure what is structure?

304
00:35:18,412 --> 00:35:24,380
对，然后说M C ts s就是个structure，a star就是另外一个另外一个算法也是个structure。

305
00:35:24,380 --> 00:35:32,280
还就觉得说这就是这些都在限制模型的思考，就包括那个之前就是open放出来一个PRM800K的一个过程。

306
00:35:32,280 --> 00:35:34,171
他也在限制模型思考。

307
00:35:34,171 --> 00:35:49,512
就他已经用一个成型的reasoning的数据集去告诉模型，你在遇到这个问题的应该先想这一步，再想这一步，再想这一步，你就限制了模型自己去search，自己去探索可能性的这种东西。

308
00:35:49,512 --> 00:35:54,136
所以说他得出的结论，欧万没有去限制模型如何思考。

309
00:35:54,136 --> 00:35:57,288
然后他又说这一点特别特别的重要。

310
00:35:57,288 --> 00:36:00,599
他所以说我们就决定不要去搞M C T S。

311
00:36:00,599 --> 00:36:10,532
我相信这个阶段他们应该是九月份欧文发布之后，他们花了很多时去研究之后，至少最晚也就到10月份吧，他们应该就决定了这个方向。

312
00:36:10,532 --> 00:36:15,676
大家想一想啊，很多团队到12月份的时候还在往mts那个路方向在走。

313
00:36:15,676 --> 00:36:22,786
但是像t力这个团队在这个时候已经找到了这样子的路线，我相信deep ck应该也是在同时间领悟。

314
00:36:22,786 --> 00:36:30,493
我我不知道是不是这样的那个学习和领悟过程哈，但应该也是领悟到了一些这样子的一些一些东西。

315
00:36:30,493 --> 00:36:38,566
所以说呢他就往后面开始在思考说嗯现在的很多的那个所谓的呃那个agent的那种，其实本质上就是个work flow。

316
00:36:38,566 --> 00:36:44,070
哎，这些agent work flow本质上也是非常struc的， 哎，所以说呢限制了模型的这个能力。

317
00:36:44,070 --> 00:36:55,345
所以说呢他们做一个判断是那种work flow的那种agent只有短期的价值，没有长期的价值是吧哈哎对对，但这是另外一个话题了哈，是讲这个这个这个agent的。

318
00:36:55,345 --> 00:37:02,580
然后他最后总结all in all是吧，我们要训个什么模型，像人类一样思考的模型，think freely自由的思考。

319
00:37:02,580 --> 00:37:15,380
然后他最后放了那个罗门那个演讲的最后一个工作，就是最后一页就是那个future work，就是他们讲那个呃他们未来要干什么啊，未来要干要干什么样子的一些一些事情。

320
00:37:15,380 --> 00:37:19,196
然后这个是这页时代子给他的最强的一个启发，什么？

321
00:37:19,196 --> 00:37:24,227
就是要用真正的激励去做强化学习，不要被那个reward model本身给限制了。

322
00:37:24,227 --> 00:37:37,932
这个这个大家现在可能理解起来有点绕哈，我给大家讲一讲啊，就是这个里面有很多算法细节今天不适宜暴露，大家可以理成我们刚刚讲的那种，对整个的那个训练过程的每一步去进行激励。

323
00:37:37,932 --> 00:37:41,228
就是比如说一个是你要想十步才能够做出来。

324
00:37:41,228 --> 00:37:47,952
但是呢之前呢我们觉得如果直接就按照最终答案去激励这个强化学习模型，我们认为有点怕。

325
00:37:47,952 --> 00:37:53,313
觉得这个中间过程那么长，我都不去管这个机器啊，那他会不会就自己学歪了。

326
00:37:53,313 --> 00:38:07,553
所以之前大家都不敢去往这个我们叫O I M，就是呃out，就是那个output reward model，就按照最终的这个这个激励去激励它，而走上了刚刚我们看到的就是open I引导大家走上的P M就process reward，就是过程激励是吧？

327
00:38:07,553 --> 00:38:14,589
啊，所以说那个时候都都在搞过程激励，但是呢他们当时得出来一个最重要的点，就是不要搞工程激励。

328
00:38:14,589 --> 00:38:20,112
我们就要去用真正的这个答案到底做对没做对，用这个东西去去激励他。

329
00:38:20,112 --> 00:38:25,979
然后那个他往下面后面也写到说当当时他们不知道deep si怎么想的。

330
00:38:25,979 --> 00:38:46,187
但是后来他们发现deep阿one那个paper里面也提到了，同样的话啊就是不要去做process，这个我们后面会会看到啊，所以他们最后就定下来了，到底我们要干什么，就是practice program就是练啊，菜就多练是吧哈哎菜就多练，就practice practice more practice。

331
00:38:46,187 --> 00:38:48,360
对，只要练就能够练出来。

332
00:38:48,360 --> 00:38:57,590
所以说呢那个他们就他们就就就想出来了这么一条路线啊，后面的就不用特别了，后面是他们在去讲他们整个训练过程，但也非常精彩啊。

333
00:38:57,590 --> 00:38:59,047
就如果大家有空的话。

334
00:38:59,047 --> 00:39:04,391
特别语声说这个还有个中文版，他是先写的中文所学那个中文版里面practice做题。

335
00:39:04,391 --> 00:39:09,897
他说模模型就非常想做题，你就告诉他做对没有然后给他一个不断做题的环境啊。

336
00:39:09,897 --> 00:39:10,058
对。

337
00:39:10,058 --> 00:39:16,050
反正这个文章后来我我们后面会发到群里面，大家可以看我觉得是一篇非常精彩的文章。

338
00:39:16,050 --> 00:39:31,751
就是他怎么去逆向思考o one，然后收集各种信息，结合自己的这个专业领域的这个知识，最后推断出一个正确的结论，这个过程非常棒啊，但是稍微有点遗憾的事情是说这个呃K1.5最后在在这个pl上做的不够彻底是吧？

339
00:39:31,751 --> 00:39:36,334
啊，就是还是呃用了用用了一些这个前置的这个激活引导环节。

340
00:39:36,334 --> 00:39:45,148
没有像那个R one一样，就是在那个训R one zero的时候，是一个完全的左脚踩右脚的这个prr l啊，当然我觉得这是一个方面了。

341
00:39:45,148 --> 00:39:53,080
另外最大的方面我觉得还是呃因为它没有开源，所以说它整个的这个在行业里面产生的impact就远小于这个。

342
00:39:53,080 --> 00:40:09,626
但是如果说你读过这篇文章，读过K1.5那个paper，他们那个report，我不得不同时对这两个团队都产生敬意啊，对对，所以所以今天表面上讲阿万，但我也还是要提一下这个呃Kimi的这个K1.5，这个这是一个非常棒的一个探索过程。

343
00:40:09,626 --> 00:40:10,320
这个正我。

344
00:40:10,460 --> 00:40:15,276
补充两句，就是12月份跟直林聊卫置，他当时在这些结果段没发。

345
00:40:15,276 --> 00:40:20,807
当时就说这个因为当时有很多人做的workflow嘛，包括这个M M C ts这些过程。

346
00:40:20,807 --> 00:40:25,445
对，当时我们就聊到说这个其实有以就是less structure，more intelligence.

347
00:40:25,445 --> 00:40:29,370
少在这个这个结构上在上雕当时去关注最后的结果。

348
00:40:29,370 --> 00:40:33,830
其实我我刚才在想，其实这边我们做公司做管理也很像，对吧？

349
00:40:33,830 --> 00:40:40,966
就是对于优秀的员工，那你就是让他去拿结果，给他充分的是，而不是将来具体怎么去做事情，对吧？

350
00:40:40,966 --> 00:40:46,497
但如果你招的是这个蓝领工人，你可能具体怎么做事情就在流水线上对吧？

351
00:40:46,497 --> 00:40:52,920
当模型的智能足够强的时候，嗯，他就是给他做题的环境，他就只想做题，就给他更好的题。

352
00:40:52,920 --> 00:41:02,578
对对对嗯，然后呢我我自己觉得一方面是没有彻底走prr l然后另外一方面我觉得还有一个原因就是没有做到同等性能。

353
00:41:02,578 --> 00:41:04,316
呃，我放到后面一起讲。

354
00:41:04,316 --> 00:41:11,849
哎，好，那我们看完了Kimi终于到了那个咱们今天的这个主角啊，对，就是到了我们deep c阿万这边啊。

355
00:41:11,849 --> 00:41:21,121
就是当时他们发了这一篇paper啊，然后大家还记得刚刚那个就是Kimi那个哥们儿分析的时候，呃，用了那个open有个video是吧？

356
00:41:21,121 --> 00:41:22,860
Don't teach啊incen是吧，要鼓励。

357
00:41:22,860 --> 00:41:29,449
Deep个are one，这个paper第一个单词就是intive Vissing啊对，就是就是激励这个reasoning capability。

358
00:41:29,449 --> 00:41:32,550
哎，对，就是这么一篇paper就就出来了对吧？

359
00:41:32,550 --> 00:41:37,976
然后呢这篇paper要讲要把它讲懂了，呃，肯定其实比V 3要要简单一些。

360
00:41:37,976 --> 00:41:42,240
但是呢仍然不是在我们今天的时间范围之内有限的。

361
00:41:42,240 --> 00:41:50,768
所以说呢我借用了这个呃呃就是他写的一篇非常棒的关于如何去理解reasonmodel这个事情里面他的一张图。

362
00:41:50,768 --> 00:42:01,435
这个图实在是写的太棒了，原因是因为你在读阿Y那个paper的时候，哪怕你就算是搞研究的人，你从头读到尾，你一定会读绕，为什么呢？

363
00:42:01,435 --> 00:42:09,970
因为你会发现在阿one最后被生产来之前，他在V 3 base和R one zero上来回的，你训我我训你，就是左脚踩右脚。

364
00:42:09,970 --> 00:42:12,551
你在读paper有时候会把自己读晕。

365
00:42:12,551 --> 00:42:19,300
所以说我发现那个sp他当时总结的这个图，哎呦，这个怎么又冒出一个什么批注功能？

366
00:42:19,300 --> 00:42:22,055
大家稍等一下，我把这个批注关一下啊。

367
00:42:22,055 --> 00:42:26,360
这个腾讯会议这产品做的真厉害，我开会的时候给你弹窗啊。

368
00:42:26,460 --> 00:42:32,490
Ok好，然后呢他这个图就完美的把阿万的整个三步的训就是三方面的训练结果。

369
00:42:32,490 --> 00:42:46,011
第一个结果是标的那个啊R R one zero，第二个是下面的那个deep sick R one，第三个是它蒸馏的那些版本，也是大家现在如果有人在本机上尝试运行的时候，应该运行的都是这些蒸馏版本。

370
00:42:46,011 --> 00:42:50,580
他这张图就完美的把这个整个这个训练过程给给弄出来了。

371
00:42:50,580 --> 00:43:03,932
那我们先看这个先看这个第一点就是也是最神奇的一点哈，也是如果你是产业界的人的话，大家可能对于这一次这个最震惊的还不是最后训出来的那个阿万，而是这个R one zero。

372
00:43:03,932 --> 00:43:05,962
这个R one zero他在干什么呢？

373
00:43:05,962 --> 00:43:10,024
就就他它简单到它简单到哈就是有点令人难以置信。

374
00:43:10,024 --> 00:43:18,885
就是Dec他们先有了一个特别强大的基础模型dic v 3，就是我们前面提到12月份发的那个按点赞的那个那个模型。

375
00:43:18,885 --> 00:43:27,192
然后呢他们在这个模型上他们用了纯强化学习，但是在这个强化学习当中，他们只干了一个什么简单的事呢？

376
00:43:27,192 --> 00:43:35,794
第一个大家看他们用了一个一个一个训练模板，这个训练模板就是呃大家我相信现在也用过很多的AI产品的是吧。

377
00:43:35,794 --> 00:43:39,542
你可大家可以理解成这个就是他的这个season prompt。

378
00:43:39,542 --> 00:43:47,572
它season prompt就是说这是一个a conversation啊between这个user和assistant啊，就是user会问个问题，然后呢assistant解决它。

379
00:43:47,572 --> 00:43:51,497
但是呢这个assistant要先think about the reasonreasoning process是吧？

380
00:43:51,497 --> 00:43:54,352
In the mind, 然后再提供给用户最后的答案。

381
00:43:54,352 --> 00:44:04,696
然后呢他要求这个assistant要把他的这个reasoning的这个过程放到那个think标签里面，要把给用户的答案放到answer标签里面，就是这么一个模板。

382
00:44:04,696 --> 00:44:13,428
他们训练的时候就是用了那么简单一个模板，然后就把那个标红的那个product t在训练的时候会换成各种各样的问题。

383
00:44:13,428 --> 00:44:15,388
比如说1加2等于几是吧？

384
00:44:15,388 --> 00:44:26,436
哎，那个那个一个方程组哎那个列出来A平方加B平方等于C啊，B等于几，大家可那个problem就换成各种各样的题，但是它的训练数据本身就这么简单。

385
00:44:26,436 --> 00:44:33,322
也也当然他们那个呃我等会就讲这是训练模板，然后完了之后他们的激励模型激励模型特别简单。

386
00:44:33,322 --> 00:44:34,903
他激励模型怎么简单呢？

387
00:44:34,903 --> 00:44:49,141
他们分成两种激励，一个激励叫准确度激励，就你这个题答对没有，但大家要记得哈，因为这个地方为了要他们不是一个就是传统意义上，比如做做pm那种做pm你因为你需要一个同等size的模型去决去判断这个过程思考。

388
00:44:49,141 --> 00:44:53,728
对，没有，他们这个只能做非常简单的rule base的基于规则的这个激励模型。

389
00:44:53,728 --> 00:44:57,841
所以他们的那个rule一定要特别的简单，要非常清晰的对还是错？

390
00:44:57,841 --> 00:45:03,077
所以他们准备的大量的前面填到这个地方的那些问题，都是有明确的对错的题。

391
00:45:03,077 --> 00:45:06,751
那什么样子的题有明确对错，数学题、物理题写代码是吧？

392
00:45:06,751 --> 00:45:08,508
这个代码有没有运行出来？

393
00:45:08,508 --> 00:45:16,175
他们相当于他们在背后准备了一个类似于像那个打信息学竞赛那样子的一个一个一个一个一个一个那种33 box。

394
00:45:16,175 --> 00:45:20,169
你把那个代码提交上去，他他就运行出来一个答案看对不对。

395
00:45:20,169 --> 00:45:25,760
或者是说他有一个那个解题的，你把你的那个答案放上去，他告诉你这个答案对不对。

396
00:45:25,760 --> 00:45:29,944
就他的这个整个这个激励模型里面，他只激励了两件事情。

397
00:45:29,944 --> 00:45:33,257
第一第一个就是说你答的对不对，一一等于几？

398
00:45:33,257 --> 00:45:37,268
模型说二啊，答对少加一分啊，如果你答错了，我我不讲分。

399
00:45:37,268 --> 00:45:38,837
还有一个激励什么呢？

400
00:45:38,837 --> 00:45:39,883
就是激励格式。

401
00:45:39,883 --> 00:45:48,776
因为他前面要求要把reasoning写到那个think里，所以说呢如果你问加一等于几，如果他直接就说answer 2，那我就给你打零分是吧？

402
00:45:48,776 --> 00:45:50,520
我不给我我不给你加分。

403
00:45:50,520 --> 00:46:02,982
但如果你除了打N 等于2之外呢，你还想啊用户问我压等于几啊，这应该是一个分简单，然后就是我想一大堆啊，这个时候我就觉得哎你的这个format这个形式是符合我的这道我就给你打高分。

404
00:46:02,982 --> 00:46:08,346
也就是说他的这个强化学习的这个激励其实非常的简单，就是判断正确还是错误。

405
00:46:08,346 --> 00:46:16,392
然后呢再搞个这个东西，然后最后再配上他们的这个呃G R P O，这个g po呢呃你把详细把它讲讲讲透了，我觉得比较困难。

406
00:46:16,392 --> 00:46:29,378
那大家记得一个简简单的一个点，就是在于说以前做强化学习的时候，根据都用的是上面的P P O，包括那个刚刚我们看那个K1.5的时候，那个那个作者也会提到说，那我们是不是用P O呢？

407
00:46:29,378 --> 00:46:39,715
啊不要对他们也他们最后也是走了其他的方式，用ppo一个最大的一个一个麻烦哈，就是在于说他本身的那个判断一个答案有没有搞对的过程。

408
00:46:39,715 --> 00:46:53,380
他那个value model本身也没有fro所以说就导致你在整个去强化学习的每一步的过程当中，你除了要调整你自己的那个policy model以外，你还要去优化那个value model整个的这个计算量开销就会特别的大。

409
00:46:53,380 --> 00:47:02,949
但加po通过一个非常粗暴的方法，就有点相当于说同样的问题扔给这个polimodel让他答八次，同样能打八次。

410
00:47:02,949 --> 00:47:04,254
压一等于几啊？

411
00:47:04,254 --> 00:47:06,211
22呃301222。

412
00:47:06,211 --> 00:47:10,778
然后呢，最后我们根据那个正确答案给一个平均值。

413
00:47:10,778 --> 00:47:13,823
然后来呃这个讲的就太痛泛了哈。

414
00:47:13,823 --> 00:47:34,390
但是大家反正基本上简单记住就是加P O是一个呃在开销上比较少，但是呢就是可以很方便的能够计算出在每一轮的这个呃强化学习探索之后，他整个离这个呃正确的方向啊到底是近了，还是呃怎么去激励这个模型往那个方向走。

415
00:47:34,390 --> 00:47:43,427
他基本就用了这三个非常简单的东西，就是一个很简单的训练模板，一个特别简单的这个激励模型和一个加修的策略。

416
00:47:43,427 --> 00:48:02,265
然后呢，他就发现只是干了这么三件事情，大家要记得啊，没有用那个什么类似于像p m 800K那样的reasoning的数据集，没有教会这个模型你什么事情要先想八步，哎，你的想法是呃first wait什么，他什么都没有教，他就是给了问题和答案和中间的规则。

417
00:48:02,265 --> 00:48:11,672
然后他们发现随着他们的训练的步那个横横横着开始steps啊，就就是那个rl的这个这个这个迭代次数学月学。

418
00:48:11,672 --> 00:48:13,345
然后呢竖轴是什么？

419
00:48:13,345 --> 00:48:21,080
是average的这个l这个response就响应的这个l所以我们就发现了一个非常神奇的一个点是什么？

420
00:48:21,080 --> 00:48:25,680
就这个模型学着学着他自己把那个答案越土越长了。

421
00:48:25,680 --> 00:48:32,349
就是说他大家大家看这个这个reward reward model啊，强化学习reward是非常重要的。

422
00:48:32,349 --> 00:48:35,146
你激励他什么，模型就会干什么。

423
00:48:35,146 --> 00:48:48,270
我们的reward reward model里面没有去reward长度这件事情，我们只判断了对错和你有没有思考，我我都我都没有判断你思考这长远短，我没有激励这个事情。

424
00:48:48,270 --> 00:48:54,080
但是呢模型自己发现了，一旦我思考的越长，我越可能把问题搞对。

425
00:48:54,180 --> 00:49:11,271
这个就是一个非常神奇的，就在阿万做出这个事情之前，全世也没有团队想到这个事情会简单到这个样子啊，就是这这这个这个曲线其实是一个非常那个的，我我觉得他比那个后面就大家传播的更广泛的那个啊哈moment那个截图其实更加让人震惊。

426
00:49:11,271 --> 00:49:13,926
最重要的一张图，这是最重要的一张图。

427
00:49:13,926 --> 00:49:26,040
但知道看图啊，就是对于很多人来说这个就是没法理解的，但是还是觉得那个啊哈moment看起来好像对于人来说比较直观，但这其实才是最最牛逼的，就是下面那个标黄的那句话。

428
00:49:26,040 --> 00:49:35,928
就说our zero就是nurse soft，就是他去解决这种需要reasoning的这种task with more thinking king time这个事情没有激励他，没有告诉他是他自己学会的。

429
00:49:35,928 --> 00:49:47,122
那么最后呢，不仅是通过这样子一张图哈，看到这样的现象，我们再看那个benchmark，上面两个是那个o one的mini和o one的0912，下面是那个R one zero。

430
00:49:47,122 --> 00:49:52,720
这个时候R one zero不是大家现在每天用的那个R one，这个时候还叫R one zero。

431
00:49:52,720 --> 00:50:05,557
然后我们就会发现，不管在ae mah gp Q A还是写代码这些，除了那个后面那个code force那个分，因为code那个还是有点有点麻烦啊，前面基本上有的超越啊，有的是逼近了。

432
00:50:05,557 --> 00:50:10,841
就用就用了这个纯rl的这个这个方法，没有灌任何的S F的数据进去啊。

433
00:50:10,841 --> 00:50:16,829
这个对于对蓄魔型稍微有点了解的同学来说应该都知道，这也是一个难以想象的。

434
00:50:16,829 --> 00:50:21,055
左脚踩右脚就就就把这个活给干上去了这样子一个事情。

435
00:50:21,055 --> 00:50:27,220
那么首先就发现这条路走对了，就在这个时候他们发现这条路走对了，这个路走对了。

436
00:50:27,220 --> 00:50:30,600
这个对算力其实也是个非常有意有好处的。

437
00:50:30,600 --> 00:50:33,980
因为对有算算力越长想的越长表现就越好。

438
00:50:33,980 --> 00:50:36,984
所以这个图其实就是那个那test time computer。

439
00:50:36,984 --> 00:50:38,862
对，然后然后呢还有一个。

440
00:50:38,862 --> 00:50:49,942
当然我这里可以简单给大家提一句啊，我没有准确的数据，因为paper里面没有公布这个这里它一共R L做了差不多应该是做了一万部的样子吧。

441
00:50:49,942 --> 00:50:56,542
其实R的成本是很低的，相比做prtrain那边的成本来说，rl的成本我我他们没有公布具体的成本。

442
00:50:56,542 --> 00:51:03,871
但我想象中啊这个rl的成本包括我也咨询了一些同学，是没有那么高的，就是这个rl的成本是一个非常低的。

443
00:51:03,871 --> 00:51:17,388
所以说如果说你现在手上有一个好的base model，你去做这样的R L的话，就相当于这个这个工作能能产生那么大impact的原因，是因为大家看到了一条低成本，然后快速提升自己base model这个能力的这个可能性。

444
00:51:17,388 --> 00:51:23,232
这里有个前提，就是说如果base model不够强，就不这个是后面要讲的一个很重要的一个点。

445
00:51:23,232 --> 00:51:28,200
对，好，那这个到到了这个地方为止呢，我们就发现哈阿文这条路走对了。

446
00:51:28,200 --> 00:51:32,654
但是呢他们发现阿文这路呢有一些问题啊，这个问题是什么呢？

447
00:51:32,654 --> 00:51:40,191
就是他reasoning的能力呃特别的强，而且自我发挥出来了很多啊，就是我们想不到的这种reasoning的这个方法。

448
00:51:40,191 --> 00:51:42,247
但是呢他有些问题是什么呢？

449
00:51:42,247 --> 00:51:47,386
就是一个是他的可读性比较差啊，第二个就是他经常会那个做language mixing。

450
00:51:47,386 --> 00:51:48,757
Language mixing什么意思？

451
00:51:48,757 --> 00:51:56,258
就是那个比较像那个上海的外企白领说话是吧呃，就是呃呃Mar啊今天这个schedule有点满是吧，就是这种这种感觉哈。

452
00:51:56,258 --> 00:51:58,962
我们就发现那个阿zero他就会很容易这样。

453
00:51:58,962 --> 00:52:03,576
而这个现象其实不仅仅翻了这个，大部分的reasoning model都会有这个问题。

454
00:52:03,576 --> 00:52:16,620
就像那个最近呃有一个有一个梗，我不知道大家有没有看到啊，舆论反转的一个就是国外有些网友截图那个欧三的那个思考过程，发现那个欧三在用英文问他问题的时候，他的reasoning过程在用中文。

455
00:52:16,620 --> 00:52:26,360
在虽我虽然我们我们知道这个真实的情况是什么哈，但是有很多国外网友在截图艾特三姆奥特曼说你们是不是在争牛deep阿？

456
00:52:26,360 --> 00:52:28,013
对，就是这个天道轮回啊。

457
00:52:28,013 --> 00:52:37,606
对，但是其实它背后的原因其实很简单，就是模型它自己在探索这个R的过程当中，对于模型来说，他自己探索出一条reasoning的一个一个路线。

458
00:52:37,606 --> 00:52:41,244
对于他来说不管是中文还是英文都只是一个token而已。

459
00:52:41,244 --> 00:52:48,356
所以说呢按照token的角度上他能思考就行了，他不管你人到底是不是能读，所以这是一个language mixing的问题。

460
00:52:48,356 --> 00:52:55,963
第二个呢就是它的格式有点混乱，大家现在用那个chat gt用cloud可能都已经习惯了，动不动就写点那个bulpoints是吧？

461
00:52:55,963 --> 00:52:59,106
动不动就是那个带down排版的特别精美的文章。

462
00:52:59,106 --> 00:53:00,760
但你看zero那个输出的话。

463
00:53:00,760 --> 00:53:07,684
你会发现因为他他只专注在解决reasoning这个事情，他的那个输出的可读性是比较差的。

464
00:53:07,684 --> 00:53:13,262
啊，那在这个时候来了，那我们为了解决呃这样子的这个问题，对不对吧？

465
00:53:13,262 --> 00:53:19,033
我要让他让这个reasoning process更readable，而要把它share给我们的open community是吧？

466
00:53:19,033 --> 00:53:25,957
那所以说呢我们继续去在R one zero基础上去做这个R one，让我们的这个这个可读性更好。

467
00:53:25,957 --> 00:53:32,584
但是说实话，最精华的工作刚刚已经讲完了，左脚踩右脚提升模型能力，这是最进化的工作啊。

468
00:53:32,584 --> 00:53:36,697
所以说真的是搞研究的人来说，其实他们最关心的是个R one zero。

469
00:53:36,697 --> 00:53:39,545
但是呢后面做R one的个过程也特别有意思。

470
00:53:39,545 --> 00:53:48,721
那我们来看看刚刚第一步讲完了R one zero怎么来的，我们现在在看这个R one怎么来的这个R one怎么来的，真的是一个非常哎呀，就是怎么说呢？

471
00:53:48,721 --> 00:53:54,100
我觉得那个把这个过程分享出来，真的就像mark Anson说的，是一个给全世界人类的财富。

472
00:53:54,100 --> 00:54:01,392
因为说实话相刚刚前面那个prr l那个过程，只要你知道了原理了，大家都能搞，但是不代表你能搞出来。

473
00:54:01,392 --> 00:54:06,254
最后这个R万你像这个这个过程，你看他们怎么去解决这些问题啊。

474
00:54:06,254 --> 00:54:18,236
首先就是既然我都已经有个R one zero了，具有这么强大的这个这个这个reasoning能力，那我去训诫那个R one的时候，我就不需要再像最开始呃从零开始做强化学习一样了。

475
00:54:18,236 --> 00:54:37,834
我先用了R one zero去生成了右边的那个呃最高的那个S F的那个data，那个code那个data那个code那个data里面就是由R one zero吐出来的一大堆带reasoning的那样子的一些一些数据，带reasoning的高带高质量reasoning的那那样子的一些数据，用那个作为code star的数据重新去s ft了。

476
00:54:37,834 --> 00:54:39,294
Deep siv 3 base这个模型。

477
00:54:39,294 --> 00:54:49,520
哎，那就是说就是这个时候你在看那个V 3和R one这两面paper的时候，你就发现一个非常神奇的事情，就是V三这个base促使了阿one的诞生。

478
00:54:49,520 --> 00:55:03,989
但是呢阿万的这个强reasoning的过程又在反向去STV3啊，所以他们俩其实又变成了左脚踩右脚啊，这个是另外一个左脚踩右脚啊，让阿万更强，同时也让V 3更强，所以说呢这个时候他们就先训了。

479
00:55:03,989 --> 00:55:18,988
第一个checpoint就是这这个红色的这个线条里面每一个小圆点，比如那个圈为code star data每一个小圆点都是一个checpoint checpoint就是说模型训练栏就有一个有个有个有个大家可以简单把它列成是一个存档嘛。

480
00:55:18,988 --> 00:55:26,400
哎对，好，第一个存档版本就是用了R one zero的高质量的code star的数据去做了一次这个S做了一个这个翻。

481
00:55:26,400 --> 00:55:34,454
然后呢他们拿着这个check point又去做了而又去做了一次像那个呃R one zero那样子的强化学习。

482
00:55:34,454 --> 00:55:38,058
但是这一次有一点点的不一样是什么呢？

483
00:55:38,058 --> 00:55:46,960
这一次的强化学习R L with accuracy format这两个不变，还是用那个答案的准确程度和格式的度来来去激励。

484
00:55:46,960 --> 00:55:51,836
但他们加了一个激励叫consistency，这个consistency是什么东西？

485
00:55:51,836 --> 00:55:53,320
就是语言一致性。

486
00:55:53,320 --> 00:56:03,975
就相当于说在这一次的rl过程当中，我不仅要求你对那个答案准确度和格式有要求，同时我要看你的reasoning过程有没有出现language mixing。

487
00:56:03,975 --> 00:56:11,396
如果你中英混杂了，我就给你打零分，你都说英文，我都说中文，我就给你打高分，哎，就是这个样子。

488
00:56:11,396 --> 00:56:14,441
也就只加这一个激励，然后呢就迅速了。

489
00:56:14,441 --> 00:56:27,380
第二个check point，这个时候的这个check point就已经其实是一个呃能力特别强的R one zero，同时还不会那个中音夹杂或者是什么什么夹杂说话的这样子的一个一个一个版本呢。

490
00:56:27,380 --> 00:56:36,628
然后呢他们拿这样子的版本又产生了第二轮的高质量cot数据，就是这个啊这个第二轮的高质量cot数据。

491
00:56:36,628 --> 00:56:40,930
这时候的这个cot数据质量比前面那个code start的好。

492
00:56:40,930 --> 00:56:42,865
那个质量高在哪儿呢？

493
00:56:42,865 --> 00:56:47,167
高就高在它的整个reasoning的过程，是语言统一的。

494
00:56:47,167 --> 00:56:54,265
哎，然后呢他们在通过人工Cherry pick呃规则匹配的各种各样的方式又删掉了一些。

495
00:56:54,265 --> 00:57:03,083
比如说觉得有些过于冗啊，想想了很多很多很多啊没必要，或者说有些可读性太差了又怎么怎么样。

496
00:57:03,083 --> 00:57:10,513
就是他是一个Cherry之后一个高质量的一个C数据，这个数据等会还有其他用，大家要把它记得。

497
00:57:10,513 --> 00:57:20,871
然后另外一方面，因为呢他希望他们这个模型大家要知道前面rl时我说了数学物理写代码都是这种题，但是他们觉得最后要给那个整个open community用是吧？

498
00:57:20,871 --> 00:57:31,067
我不能说我这个模型只能干这些东西，还是要干一些泛化性的东西，比如一加一等于2是吧，北中国的首都是北京，哎，或者是说一些一些正常的通用的题。

499
00:57:31,067 --> 00:57:39,718
所以它同时又从被已经被他们强化过一轮的V 3 base，又去输出了一些通用knowledge的S F数据，也就是这一份。

500
00:57:39,718 --> 00:57:48,622
然后用这两份高质量的C O T和那个通用世界知识的这两个数据加起来，一起去做了最后一次的强化学习。

501
00:57:48,622 --> 00:57:54,558
然后在这一次的强化学习里面，就更像正常的我们去训一个model的样子啊。

502
00:57:54,558 --> 00:58:07,546
就是有包括你看他有human preference是吧，就把我们人对于这个东西，你们包括格式是吧，输出的格式啊，各种各的东西，最后拿出来的东西才是大家现在用到的那个deep sick R one。

503
00:58:07,546 --> 00:58:10,925
啊，所以说这个也你也可以说这个阿万不干净啊。

504
00:58:10,925 --> 00:58:13,290
对，但但是它整个过程就是这样的。

505
00:58:13,290 --> 00:58:15,487
为什么我说这个过程很重要呢？

506
00:58:15,487 --> 00:58:24,949
是因为如果你的迅模型的过程中，你就会去知道从一个步骤从R one zero到走到R one，大家先在用的那个过程其实有这是他们的探索路线。

507
00:58:24,949 --> 00:58:30,355
但如果他不跟你讲啊，其实你有很多种不同的探索路线的，你不一定搞得准的。

508
00:58:30,355 --> 00:58:34,580
但这四界他把整个那个过程我我们二是这么给给大家讲的。

509
00:58:34,580 --> 00:58:49,920
但如果说你真的回到那个就是deep自己的那个paper里面啊，你去看他们就是在做我刚刚说的那个事情啊，就是our zero在这一步已经训完了，然后呢他们在这里在搞那个啊our用our zero训our one的这个过程啊。

510
00:58:49,920 --> 00:59:05,260
他们怎么讲啊，我们怎么去构建我们这个code start的数据啊，这个数据我是我是怎么样子弄的，我我构建这个数据的时候我关注什么呃，然后那个呃那种我怎么样去做这个reasoning oriented的这个强化学习。

511
00:59:05,260 --> 00:59:17,804
呃，然后呢我我怎么去准备那个刚刚我说的那两个部分的data，高质量的reasoning data和那个从V三那边拿出来的那种就是非reasoning的世界通用知识的data，我该怎么样子去怎么样去准备啊？

512
00:59:17,804 --> 00:59:25,396
然后最后为了面向各种各样的场景，而不只是数学写代码，我怎么样面向这样的场景去做R L他写的非常详细。

513
00:59:25,396 --> 00:59:43,865
就是对于真的想复现工作的时候，这些东西当然还没没有K1.5详细，但是他已经写的非常的好了，所以这是第二步，就他们怎么拿出来R万的好，然后这个时候就来了特别有趣的第三步，这也是deep si阿one这个工作我觉得首先在学术界和技术界破圈一个最重要的事情。

514
00:59:43,865 --> 00:59:50,079
如果他只做到这一步，我觉得也许啊当然这工作其实已经很重要了，我觉得也许也能破圈。

515
00:59:50,079 --> 00:59:53,942
但是如果没有最后这一步的话，我觉得概率上会低很多。

516
00:59:53,942 --> 00:59:58,141
所以第三步我觉得是他们破圈的一个非常重要的一个动作。

517
00:59:58,141 --> 01:00:03,684
第三步啊，不好意思啊，对我我刚刚准备了三个那个让大家看得清楚那一个check point。

518
01:00:03,684 --> 01:00:09,020
哎，好，做完这个第二步拿到阿万之后，我们再来看阿万的这个表现。

519
01:00:09,020 --> 01:00:21,220
刚刚前面那个是阿L哈，阿万就是做完那个之后，大家可以看在所有的分数上都全面的呃，除了那个gp gp Q A啊，那个还差那个O万0912一点点。

520
01:00:21,220 --> 01:00:28,420
在其他方面的数据，甚至连最后的那个code forces那个数据都已经全面超越O系列模型了。

521
01:00:28,420 --> 01:00:33,647
这个就是加R L的这个这个威力啊，对，这这这是这个样子又上了一个高度。

522
01:00:33,647 --> 01:00:40,206
好，最后就到我刚刚跟你说的，跟大家说的最有趣的一个部分，就是明明做到这里就够了，是不是啊？

523
01:00:40,206 --> 01:00:42,665
正常的工作做到这里已经很完整的。

524
01:00:42,665 --> 01:00:48,241
这个paper本身已经够牛逼了，结果呢他们还做点额外的工作，他们干了个什么事儿呢？

525
01:00:48,241 --> 01:01:00,688
他们用刚刚我们说的呃中间一个check point产生的那个呃R one zero到R one做一个中间版本生成的高质量C T数据和V 3的这个世界通用制这两份超高质量的S F data。

526
01:01:00,688 --> 01:01:07,140
他们拿这个东西不去微调他们自己的V 3，他们去微调别人的模型。

527
01:01:07,140 --> 01:01:23,248
因为他们想验证一个事情，就是说呃虽然你们这些模型没有做rl没有做这个纯强化学习，但是呢我这边有一个超级厉害的这个这个这个这个reasoning model的老师输出的这些reasoning data，你能不能学会我的这个reasoning的过程。

528
01:01:23,248 --> 01:01:30,683
他们想去研究这个事情，他们不仅想，他们还做，他们做了之后呢，还把做的那些那些模型全都放出来了。

529
01:01:30,683 --> 01:01:34,755
所以说这里就产生了一个特别奇妙的一个一个效果哈。

530
01:01:34,755 --> 01:01:49,592
就是首先你看他们做，他们拿着那个他们的那个阿万产生的那些高质量数据去那个增馏了千万从1.5B到那个7B的max到14B32B然后还去做了那个呃，因为千万更多是我们这个中国嘛是吧哈。

531
01:01:49,592 --> 01:01:57,236
对对对对，呃，但其实千万也是全球啊，千万在那个整个global的这个community里面，还是非常有impact的一个工作啊。

532
01:01:57,236 --> 01:02:00,973
但是但是你要真的要要破圈，光做千万也还不行是吧？

533
01:02:00,973 --> 01:02:05,900
他们也还还得还得做做拉嘛啊但是我觉得做拉完全就是属于羞辱拉。

534
01:02:05,900 --> 01:02:19,816
因为因为因为大家大家可以看哈，同样是用这个高质能数据去做去做蒸馏，大家有没有发现拉玛70B的表现在有些事情上还不如千问32B就大家都用同样的数据去去去蒸馏。

535
01:02:19,816 --> 01:02:29,338
比如在第一个那个am M E的PaaS at one的这个上面，他他就输他就输了啊，当然他那个consist 64是赢的哈，但是整体是非常接近的。

536
01:02:29,338 --> 01:02:39,360
比如说后面那个ma是500，前文32倍是94点3分，那么70B是94点5分啊，所以说这个工作重要的意义是什么哈？

537
01:02:39,360 --> 01:02:51,326
首先deep sike除了搞完自己的工作以外，他还向整个世界证明了一个事情，就是一个超大size的高质量的reasoning model产生出来的reasoning data。

538
01:02:51,326 --> 01:02:55,979
仅用这个数据去做s ft打造S F的成本是超低的。

539
01:02:55,979 --> 01:03:04,575
相比这个prtrain来说，就已经能够把现有的很多模型的表现给拔地而起了，这个都不用做R L啊。

540
01:03:04,575 --> 01:03:10,180
然后同时呢为什么我说这个工作这个工作很重要的另外一个原因是什么呢？

541
01:03:10,180 --> 01:03:14,909
就是他让大家看到了在自己的电脑上去复现这个结果的可能性。

542
01:03:14,909 --> 01:03:22,792
就是大家知道技术社区不是每个每个那个research的家里面都有八张A版，有很多时候大家要去复现一个工作。

543
01:03:22,792 --> 01:03:28,397
哎，你你这哦你这里有个那个32B的版本啊，我我直接那个什么lstudio是吧？

544
01:03:28,397 --> 01:03:31,725
欧拉嘛拉下来，本地就开始部署起来，就开预警。

545
01:03:31,725 --> 01:03:36,280
然后一看我靠，就是因为因为那个千万和那个拉都是开源的嘛。

546
01:03:36,280 --> 01:03:45,099
大家很容易就可以对比出来，就是他这个原始版本和这个经过经过这个R万蒸馏之后的这个版本，你一一下就搞特明，哇，这个这个方法真的有用。

547
01:03:45,099 --> 01:03:51,860
这个中国团队的工作看来真的是很厉害啊，他们s ft t一下都这么厉害，他们原版该得该得多厉害啊，是不是啊？

548
01:03:51,860 --> 01:03:54,506
所以说他们这个工作我觉得最后能大破圈。

549
01:03:54,506 --> 01:03:57,740
还有一个非常重要的事情，就是做了这个部分的工作。

550
01:03:57,740 --> 01:04:07,640
哎，当然哈这个部分的工作呢啊在接下来半个月啊，因为这个事情确实已经完全不受他们控制了，呃，也产生了一些呃我觉得也不知道真的还是负面吧。

551
01:04:07,640 --> 01:04:12,209
等会儿我们有个后面一个话题，专门讨论这个蒸馏这个事情。

552
01:04:12,209 --> 01:04:15,864
哎，好，那到这个地方呢基本上也就差不多了是吧？

553
01:04:15,864 --> 01:04:25,733
但是呢除此之外呢，就是这个图上面东西我们讲完了，但是deep stick还做了一点额外的工作，这个国外的工作就会影响我们走向下一个。

554
01:04:25,733 --> 01:04:39,391
就今天分享的第二个高潮的一个话题啊，就第一个呢是他们在他们的paper里面提到他们他们那个我给大家看一下这个看我们直接看原文吧啊特别有意思啊，就是阿万的这个paper原文。

555
01:04:39,391 --> 01:04:49,560
这个后面这个地方就是他们说那个呃最后这个discussion啊，他们有讨论说呃做蒸馏还是做这个强化学习，最后呢有一个不太成功的尝试。

556
01:04:49,560 --> 01:04:55,734
就是他专门有一张不太成功的尝试，然后这个里面讲了两个不太成功的尝试。

557
01:04:55,734 --> 01:04:57,663
第一个prr m process reward model。

558
01:04:57,663 --> 01:04:59,014
啊，原因是什么呢？

559
01:04:59,014 --> 01:05:15,800
是因为他说我们发现就是太难去定义，就是比如比如说你你你可能那个一个一个东西，你你你你脑内reasoning是吧认定了800字，你你光是把这800字给分出步骤来都很难，然后怎么去给每一个步骤打分，对不对？

560
01:05:15,800 --> 01:05:23,256
有时候可能我开始想歪了，但也许就是因为我前面想歪了，才让我后面能想到正确答案，那我怎么样子去给前面打分呢？

561
01:05:23,256 --> 01:05:28,430
这个东西就就就非常难做啊，或者是说你就要有大量的人去做这个pm数据的标注。

562
01:05:28,430 --> 01:05:32,691
这个在那个资金成本和时间成本上其实都是不太可控的一个事情。

563
01:05:32,691 --> 01:05:35,582
所以说他们觉得pm他们做不下去，这是一个点。

564
01:05:35,582 --> 01:05:43,897
第二个点就是讲那个蒙特卡罗苏搜索，就是M C T S为什么他们做不下去，这个里面啊大家不用特别具体去了解那个东西。

565
01:05:43,897 --> 01:05:47,135
但是有一个点我觉得是能给大家讲明白的。

566
01:05:47,135 --> 01:05:50,553
为什么在语言模型里面做mts很难做摩卡搜索？

567
01:05:50,553 --> 01:05:51,992
我们简单去理解它。

568
01:05:51,992 --> 01:06:04,945
案就是说我当下在下这一步棋的时候，比如以前就是用到那个阿尔法go里面是吧哈那就是因为棋盘上大家想啊棋盘上那个能落子的空间是一个有限的，这个大家能想象吧？

569
01:06:04,945 --> 01:06:05,844
棋盘上能么？

570
01:06:05,844 --> 01:06:13,400
也就是说我我每次最多搜索什么，围棋的规则是确定的，只能放在那个还有空位的地方把棋子落下去。

571
01:06:13,400 --> 01:06:21,994
而棋盘的格子数有是有限的那它的整个的搜索空间啊，当然你如果你要把它长度放长，那确实有无限的可能性。

572
01:06:21,994 --> 01:06:25,171
但是它当前每一步的搜索空间是有限的。

573
01:06:25,171 --> 01:06:31,710
但是大语言模型，大家如果对于大语言模型的推理next token prediction有一个最基本的理解。

574
01:06:31,710 --> 01:06:41,240
你们应该都能想到每一次推理的时候，每一个next token推理的时候都是整个vocabulary，是不是就整个词表，每一个可能性我都能去。

575
01:06:41,240 --> 01:06:44,989
那而而而且而且它的规则还没有像围棋那样的规则。

576
01:06:44,989 --> 01:06:50,953
那这个时候的话，你你用你在大语模型上面next open protection去做这种摩托卡数入的搜索。

577
01:06:50,953 --> 01:06:58,281
你最后就发现整个量非常难控制啊，然后你也很难去定义那个激励激励模型，就888整个的一些事情。

578
01:06:58,281 --> 01:07:12,113
但是呢大家可以想象就是他们放出来这一篇的时候，说我们觉得P M M的字，他们虽然没有把那个话说死哈，他们说呃呃我们说我们搞不通，并不代表这两个路线不行，但是大家都懂的是吧？

579
01:07:12,113 --> 01:07:18,828
已经有个成功版，就是我相信意思半会现在可能很多之前在做pm M C T很多现在都特别崩溃是吧？

580
01:07:18,828 --> 01:07:21,613
都赶紧转头要要来要来整O M这个方向。

581
01:07:21,613 --> 01:07:29,801
嗯，对，所以一方面呢他们在那个工作里面告诉大家，就是我们也试过P M M C T S，我们觉得我们搞不定啊，你行礼尚对吧？

582
01:07:29,801 --> 01:07:31,603
啊，哎对对对，好，这个没什么。

583
01:07:31,603 --> 01:07:38,416
最关键的是他们在他们的这个里面，他们还做了一点微小的工作啊，这个微小的工作是什么呢？

584
01:07:38,416 --> 01:07:43,500
我们前面提到他是不是拿了高质量的数据去S F了别人家的模型。

585
01:07:43,500 --> 01:07:57,149
那这时大家肯定心里有个疑问啊，你用这个H做S F别人家的模型，你为什么不用你们训R one zero那个思路，用纯R L纯那个强化学习也去整一整别人家模型呢？

586
01:07:57,149 --> 01:08:13,379
Deep说ok我确实想了，我也做了这个地方，就是呃第二个模型就那个deep R one zero 千万32B他这个就是他们拿千万32B作为base model，然后用了一模一样的R L的方式去做，结果发现没有提升。

587
01:08:13,379 --> 01:08:15,177
大家大家大家看到了吗？

588
01:08:15,177 --> 01:08:29,566
那个第二个就是那个R one zero千问32B下面那个是distill千吻32B那个R one zero那个就是用纯R L训出来的，distill那个就是没做R L而是用了那个高质量的那个co t数据去S F出来的。

589
01:08:29,566 --> 01:08:32,263
那个千文32B都是同样的base model。

590
01:08:32,263 --> 01:08:36,939
你看他们的那个奔驰mark的那个得分差距差的有有有有有多大。

591
01:08:36,939 --> 01:08:43,475
对所以这个时候他们得出了一个结论是说，哎这个左脚踩右脚啊也要有一个基础啊。

592
01:08:43,475 --> 01:08:49,459
但其实这个道理上比较好理解啊，就像那个皮给我给我讲的一个点是什么呢？

593
01:08:49,459 --> 01:08:57,872
就大家不要把那个reasoning呢想真的想成是一个人在思考，没有这个东西，reasoning也就是next token prediction的一部分。

594
01:08:57,872 --> 01:09:11,846
只不过呢我们是通过让模型去产生更长的前面的C O T，让他有更多犯错搜索的空间和思考的这个这个这个基本的信息的可能性，让他更容易猜得出来或者是说推得出来这个正确答案。

595
01:09:11,846 --> 01:09:18,524
如果你的base model不够强，我们打个比简单的比方，我们给一个二年级的小朋友一道大学高数题。

596
01:09:18,524 --> 01:09:24,497
我们最后把它关到房间里面一个月，让他一直想，我相信他也是想不出来的，对不对？

597
01:09:24,497 --> 01:09:28,363
所以说呢P1二这个事情对于base model本身是有要求的。

598
01:09:28,363 --> 01:09:32,580
好，那为什么我说这个地方会引入我们下一个第二个高潮？

599
01:09:32,580 --> 01:09:46,483
一个很重要的原因就是我们发现以这一切的起点，就我们前面一直在讲阿万，但是阿万的一切的起点都是deep v三这个671B的moe模型。

600
01:09:46,483 --> 01:09:59,460
我们发现我们让不过去这个模型啊，并不是说阿one就是靠自己啊pr l就左脚材料就升天了，没有这个强大的base model，他搞不出来现在这样的工作。

601
01:09:59,460 --> 01:10:08,960
所以这是为什么前面我提到K1.5啊，除了他没用P2以外，我觉得还有一个很大的一个原因啊，是也许啊我我也不知道内幕，因为没开源是吧？

602
01:10:08,960 --> 01:10:14,819
啊，也许啊就是k的这个base model可能没有做到V三这样的高度，这也是一个极大的一个可能性。

603
01:10:14,819 --> 01:10:17,669
那么下面我们就来进入到今天的第二高潮。

604
01:10:17,669 --> 01:10:32,968
就阿万讲完了，就我们发现阿万不是罗马不是一天建成的，就是当时那个东西破圈了之后哈，就是美国那边有很多的叙事说哦太神奇了，deep好像是中国一个量化基金的site project，哎，他们就随便搞了一搞哈，这个东西就出来了。

605
01:10:32,968 --> 01:10:42,928
虽然这个故事听起来很符合这个好好莱坞叙事哈，但是说实话就是如果你不认真的去对待一个一个工作的话，其实我觉得有时候是是贬低它。

606
01:10:42,928 --> 01:10:51,200
我首先我们是一个非常serious的在探索A G I在在搞模型研究这么一家公司，而他们在这个上面的投入是非常长期的。

607
01:10:51,200 --> 01:10:58,780
而且他们的很多的贡献并不是在阿湾这一个地方体现出来的那我们就来看一看罗马虽然不是一田建成的，我们看看他是怎么建成的。

608
01:10:58,780 --> 01:11:04,993
在阿湾的背后有几个非常关键的几个东西，第一个是在那个呃去年2月份的时候，他们发布deep mess。

609
01:11:04,993 --> 01:11:09,809
但那个那个那个里面他们为了解决那个数学题嘛，他们就引入了这个g po。

610
01:11:09,809 --> 01:11:18,664
G po虽然好用是好用啊，效率很高，但还有个问题就是呃他基本上只能解那种就是呃答案特别明确，就我们说的数学物理啊那种类型的题。

611
01:11:18,664 --> 01:11:25,810
呃，所以他们当时做deep ma的时候，他们引入了这个G p的这个方法，极大的降低了这个强化学习的那个运算运算量啊。

612
01:11:25,810 --> 01:11:30,160
但那个paper是二三年其实就已经发了，只不过这个模型上二分开源的。

613
01:11:30,160 --> 01:11:42,421
然后五月份的时候他们发布了deep sick v 2，这个其实是一切的起点，因为他们在V 2里面引入了deep sick和moe这几个概念，我们等会都会挨个过啊，大家我们现在只是快速过一下。

614
01:11:42,421 --> 01:11:59,654
然后M L V这个方法，然后呢在去年12月份发布了V 3，引入了F P8训练和m tp这样子的训练和推理方法，这些全部都是最后构成了一个那么强大的V 3模型，作为R基础的潜锁店，然后呢加P我们前面讲了，所以我们现在就跳过。

615
01:11:59,654 --> 01:12:02,212
我们先看deep sick moe为什么它厉害？

616
01:12:02,212 --> 01:12:04,180
它到底解决了什么东西？

617
01:12:04,220 --> 01:12:09,821
呃，可能有些同学还不知道什么是moe哈，就是他叫mixture of experts，就是混合专家模型。

618
01:12:09,821 --> 01:12:10,669
什么意思呢？

619
01:12:10,669 --> 01:12:17,798
啊，就是我们后来呃就就是就嘛哈大家都会觉得说那这个模型这个尺寸越来越大，能力肯定越来越强。

620
01:12:17,798 --> 01:12:25,605
但是呢后来大家就会发现哈，就是你的模型尺寸太大了之后啊，就是这种我我们觉得这种模型训练越来越难了。

621
01:12:25,605 --> 01:12:32,055
就是你每一次那个你训大家知道所谓的模型就是一堆的这个矩阵嘛，里面存了很多的的数。

622
01:12:32,055 --> 01:12:39,351
那你这个东西太大了之后，我每次训练单个to窥训练都要把整个模型全部那个呃forward back backword一次是吧？

623
01:12:39,351 --> 01:12:43,971
这个运算量更新的些数据量太大了，所以越训越懒，很容易迅崩。

624
01:12:43,971 --> 01:12:51,434
所以后来呢就但是也不是后来啊，M1的概念好像是60年代70年代就有了吧哈这是个老概念了。

625
01:12:51,434 --> 01:13:06,360
但是呢最近几年第一个把它拿出来让业界的关注的就是Mr是吧哈欧洲之光哎，对Mr做的那个八成7B的那个那个moe啊，他就会发现说哎其实不需要每次推理的时候或者训练的时候都要激活整个模型。

626
01:13:06,360 --> 01:13:09,588
哎，其实我可以把整个模型给我把size做的比较大。

627
01:13:09,588 --> 01:13:21,534
比如说我做成一个七八五十六B但是呢我每次可能只激活其中一个专家啊，我激活只只激活一个7B这样我训练的时候我的开销小很多，我推理的时候呢我的开销也要小很多。

628
01:13:21,534 --> 01:13:34,610
这样子我可以保证我在训练的时候更更不容易把这个模型迅崩，这是之前的一些探索啊，做了8乘7B8乘22B然后后来那个是吧还有那个腾讯去年底趁着那个放假前赶紧开了那个会员。

629
01:13:34,610 --> 01:13:40,098
嗯，那个会员就是个三百多币，三百多币的个一把我忘了啊，反正有很多的这种探索。

630
01:13:40,098 --> 01:13:44,550
哎，但是呢之前的moe的有些问题，就一个是专家数大都不多是吧？

631
01:13:44,550 --> 01:13:54,334
像的8乘7B8乘22B都是有八个专家啊，它的稀疏度其实还不够啊，然后呢也很难把总总的这个size给训霸，这是之前的大概的情况。

632
01:13:54,334 --> 01:13:58,110
那deep simoe就是他们的V二那个里面他们干了什么事情？

633
01:13:58,110 --> 01:14:03,259
第一个就是他们超大规模V 2的时候，就已经是一个236B了啊。

634
01:14:03,259 --> 01:14:09,610
然后每次真的运行的时候，激活20 21B到V 3的时候就已经到了671B了。

635
01:14:09,610 --> 01:14:16,679
据据我所知哈呃是是那个就是这一代的这个moe里面应该是最大的这个这个赛的moe模型。

636
01:14:16,679 --> 01:14:21,938
然后呢呃单次激活是呃37B对，然后他们还做了很多的创新。

637
01:14:21,938 --> 01:14:41,420
呃，首先给大家那个呃解决一个概念是今天早上我们在另外有个群里面讨论的时候，就是呃很多人觉得mo一很low，哎，觉得就是大模型训不下去了，就续一堆小模型，然后好像试图就是三个臭皮匠啊，就是我操我都忘了三个吧，凑诸顶个诸葛亮是吧？

638
01:14:41,420 --> 01:14:48,487
其实也不是一样的，大家脑子里面想到mixture of experts的时候，通常会想歪的原因是什么？

639
01:14:48,487 --> 01:14:51,516
是大家脑子里面的moe是有八个专家。

640
01:14:51,516 --> 01:14:55,958
哎，然后我每次来就问这个专家，专家就给我答个问题。

641
01:14:55,958 --> 01:15:04,373
No不是这样的，模型是分很多层的，这些并不存在一个大家想象中的那个expert，是每一层里面都分了八个。

642
01:15:04,373 --> 01:15:10,232
当然当然哈在那个deep moe里面里面V三里面他们就有200 200 256个吧。

643
01:15:10,232 --> 01:15:14,494
我我印象中应该是啊，他就每一层都有256个块儿。

644
01:15:14,494 --> 01:15:22,484
呃，然后它有很多很多层一个token进来，在每一层都会被分配到不同的所谓的这个expert的那那个那个块里面去。

645
01:15:22,484 --> 01:15:30,830
也就是说你一个token进去处理完了之后，其实在整个那个多层里面是经过了很多个不同的专家，所谓的这个expert的。

646
01:15:30,830 --> 01:15:38,352
我觉得这个名字取的有点有点误导大家，大家老子觉得哎呀好像好啊，呃就是用这种方法来来来拼凑字。

647
01:15:38,352 --> 01:15:44,453
其实不是的，它只是一种把这种denmodel变得更加稀疏，那更加好训的这样子一个一个方法。

648
01:15:44,453 --> 01:15:55,976
好，那在在在这个deep moe之前呢，大家的做法都是一个token进来之后，就直接有一个路由器，一个Roter就把它扔到我说的这八个或者256个专家之一，就直接扔过去了。

649
01:15:55,976 --> 01:15:59,535
但是呢在V 2和V3里面他们有个创新是什么呢？

650
01:15:59,535 --> 01:16:10,802
他们在直接用Roter去把这个token扔给那些专家之前，在V二里面他们加了一层F在V三里面他们在前面加了三层F呃，大家可能有些时可能完全不理解F是什么。

651
01:16:10,802 --> 01:16:15,320
你可以理解就是说他在mo一前面加了个小模型哎，加了个小模型。

652
01:16:15,320 --> 01:16:19,144
这个小模型呢大家知三层F完级干不了太多的事儿。

653
01:16:19,144 --> 01:16:24,879
但是呢他也能够去理解很多我们所谓的这个黑灯space啊，浅空间的一些一些概念。

654
01:16:24,879 --> 01:16:30,788
也就是说之前的就非常粗暴的把一个token来了，就是说李归的个专家李归的个专家。

655
01:16:30,788 --> 01:16:37,740
今天早上在我们有个讨论群里面，压哥提出来了一个非常有趣的，就是把moe比作在医院里面看病。

656
01:16:37,740 --> 01:16:47,333
啊，就像是一个人去医院看病，以前呢就是这个医院只有全科医生，所以说呢每个人来这都要都要去把那个全科医生叫过来啊，他效率很低嘛。

657
01:16:47,333 --> 01:16:55,603
所以后面做了moe之后呢，相当于说就是有个分诊台啊，然后呢这个分诊台呢他就会把你分到不同的专科医生那个地方去。

658
01:16:55,603 --> 01:16:59,738
然我他当时写了一篇文章呢，我就给他做了一点小小的补充。

659
01:16:59,738 --> 01:17:10,297
我说deep moe在这个上面还有一点创新，就以前的分诊台是站了一个完全没有医学知识的保安，哎，他只是看哪个科室闲就把你就把你扔到哪个科室去了啊。

660
01:17:10,297 --> 01:17:19,047
但现在gi这个M他们有个小创新是分诊台那占的是一个有医学知识的呃医学院的本科生吧，哎他是有一些基本的这个知识的。

661
01:17:19,047 --> 01:17:27,629
所以说呢他在就是把你往后面这个分流啊，或者这个事情上面，他有一些自己的一些想法，哎，对对对，就会处理的稍微好一些。

662
01:17:27,629 --> 01:17:30,321
然后他们他们的第二个创新是什么呢？

663
01:17:30,321 --> 01:17:36,505
就相当于说是那个shared experts，就之前的moe呢都是相当于说呃都是把每个专家都是分开的。

664
01:17:36,505 --> 01:17:45,580
他们在你看右下角那个图里面，他们那个绿色的部分share experts是在每一层那个你的那个token去的时候，这个share experts是一定会被激活的。

665
01:17:45,580 --> 01:17:50,860
就就是这样子的话，相当于说就有一些可能通用的一些我们要打引号啊能力。

666
01:17:50,860 --> 01:17:55,480
因为大家一般想到虚模型能力的时候，老会想一些特别具体的能力。

667
01:17:55,480 --> 01:18:02,740
但其实有时候不是这样啊，就有些通用的一些所谓的这个打引号的能力呢，他们就会被这种share expert所共享。

668
01:18:02,740 --> 01:18:08,680
哎，然后他们还发明了一个特别粗暴，但是特别实用的Roter分流算法啊，我也不想再细讲了。

669
01:18:08,680 --> 01:18:19,809
然后他们搞了一个特别极致的跨节点通信效率的方案啊，就用了那个那个Amvia收购的那家公司的那个ib infinity band啊infinity band去和nv link去做。

670
01:18:19,809 --> 01:18:33,920
然后呢，就是在最后这一点，就是这个极致的跨节点通信效率上面，就是大家现在在媒体上经常容易看到的，说什么那个呃deep stike绕过的哭大哎，在底层去写P T S啊那些事情。

671
01:18:33,920 --> 01:18:39,809
嗯，我在这里之所以不想detail的现状，是因为这里面每一个展开都有特别多的算法和工程细节。

672
01:18:39,809 --> 01:18:42,225
但是它的paper里面读起来实在太精彩了。

673
01:18:42,225 --> 01:18:46,000
但如果我们今天要把这个搞完的话，这个时间确实是不够了。

674
01:18:46,000 --> 01:18:49,624
但是我真的是对于有兴趣的同学，我是非常推大家去读的。

675
01:18:49,624 --> 01:18:53,701
然后呢，但是我这个里面每一个东西，我们等会儿还会回过头来看。

676
01:18:53,701 --> 01:18:55,211
为什么要回过头来看哈？

677
01:18:55,211 --> 01:18:56,268
等会大家会知道。

678
01:18:56,268 --> 01:19:01,251
但你们要知道他们M E做这些创新，这些东学都非常厉害，这些中西基都是M1。

679
01:19:01,251 --> 01:19:08,525
这个架构可能大家已经探索了一年多了啊，没有谁在这个这个尺度上六百多B的这个尺度上真的去去搞过这些。

680
01:19:08,525 --> 01:19:13,028
而且他们在工程上和实验上已经做了大量的hard work和这个创新。

681
01:19:13,028 --> 01:19:20,995
因为他们在paper里面提到，他们最终在训最后那轮V 3的时候，都没有出现过那种大规模的迅崩，一次就训过去了。

682
01:19:20,995 --> 01:19:25,844
这也是他们最后为什么能五百多万的训练成本的一个很重要原因。

683
01:19:25,844 --> 01:19:31,386
第二个是那个M V，M V就更圈算法，但是呢我可以跟大家讲M的意义是什么？

684
01:19:31,386 --> 01:19:39,213
嗯，如果研究过这个transformer同学应该都知道transformer里面一个非常重要的这个多头注意力模块mha a对吧？

685
01:19:39,213 --> 01:19:44,315
呃，mv是m的可以理解成是一个替代的一个东西，他干的事情是什么呢？

686
01:19:44,315 --> 01:19:51,422
就现在的模型在推理的时候，其实对于GPU的那个显存占用，模型本身的尺寸一定是占最大头的。

687
01:19:51,422 --> 01:19:57,800
但是随着现在那个使用场景越来越宽泛，用户越来越喜欢跟模型聊越来越多的东西。

688
01:19:57,800 --> 01:20:03,510
其实显存里面除了存了模型的权重以外，有百分之三四十的空间都在存上下文。

689
01:20:03,510 --> 01:20:10,605
上下文里面很多就是通过kv case的方法存在这个存在这个mh a的这个多头注意力这个矩阵里面的。

690
01:20:10,605 --> 01:20:13,374
而他们这个M这个工作是干了什么呢？

691
01:20:13,374 --> 01:20:17,181
他们是用时间换空间，就是训练的时候多花一点时间。

692
01:20:17,181 --> 01:20:44,777
但是呢他们最后就是最右边的这个M V的这个东西，大家可以理解成他把一个本来是一个呃比如说是M乘N的这样子的一个矩阵，直接压缩到了一个一个lower a一个一维的一个一个一个一个一个一个low rank的一个这样子的一个一个一个上面，这个压缩率非常的高，从而就使得他最后在推理的时候，就是这个磨型去推理的时候，它的K V比别人要小。

693
01:20:44,777 --> 01:20:54,120
那么这样子他在单卡上面它的它能够承载着上下文，或者是承载的用户并发数就会变多，这是一个非常重大的创新。

694
01:20:54,120 --> 01:20:57,681
因为他们不仅压缩了尺寸，能够存在更多的推理。

695
01:20:57,681 --> 01:21:03,736
而且在他们的这个evaluation测试当中发现相比mh性能不仅没有下降，甚至还有上升。

696
01:21:03,736 --> 01:21:12,283
就是performance指的不是说那个呃工程上的，就是不是那个运行上的performance，而是说是自智力能力方面并没有出现下降。

697
01:21:12,283 --> 01:21:16,201
啊，这个我相信很快也会成为一个大家都会用的东西。

698
01:21:16,201 --> 01:21:21,078
然后第三第三个就是那个他们在V 3里面引入了呃F P8训练啊。

699
01:21:21,078 --> 01:21:25,027
F P8训练这个东西啊，我简单给大家介绍下是什么啊？

700
01:21:25,027 --> 01:21:31,035
就是我们以前那个模型里面训练，大家看下面那张图啊，就是这个是个混合精度训练。

701
01:21:31,035 --> 01:21:36,357
就我们现在训练的时候呢，就里面既有那个32位浮点，也有16位浮点。

702
01:21:36,357 --> 01:21:45,456
大家知道这个对计算机知稍微还记得一点点的就是几几个点伏那个几位那个浮点，就是你用了几位数去表达一个浮点数是吧？

703
01:21:45,456 --> 01:21:53,341
就是那个呃比如说零点几几乘以十的几次方是吧，就那个样子，八位浮点其实能表达的精度下降的非常非常的多。

704
01:21:53,341 --> 01:22:00,834
所以说之前的那个大家在训模型的时候，如果你的参数啊是存在这种八位浮点的话，你通常是迅速出来模型的。

705
01:22:00,834 --> 01:22:12,727
因为它能够表达的精度太浅了啊，按照我们现在这种大规模训练，它就扛不住，所以大家训练都还是16位精度啊，而这个图里面包括还有一些32位精度的这样子的浮点数。

706
01:22:12,727 --> 01:22:16,800
但其实呢其实nd亚一直在推广大家去训那个F P8，哎，但是。

707
01:22:16,800 --> 01:22:17,608
怎么说呢？

708
01:22:17,608 --> 01:22:22,054
就是很简单，就是菜，就绝大部分团队搞不定这个事情。

709
01:22:22,054 --> 01:22:29,936
因为大家要想一想什么，就以前整个的这个这个这个行业，大家都是在16和32上面训的。

710
01:22:29,936 --> 01:22:39,232
现在我告诉你说这个中间部分的那个算子部分的运算过程，你可以用八位浮点去运算，到底是哪个部分可以呢？

711
01:22:39,232 --> 01:22:45,700
没法知道，而且有可能在前面某一个算子换到8位浮点之后，后面整个都崩了。

712
01:22:45,700 --> 01:22:48,751
但你也不知道到底是哪个地方导致的。

713
01:22:48,751 --> 01:22:58,285
所以说他们deep pzi这个团队可以说是第一次在那么大规模的模型里面，真的把F P8混合精度训练这件事情给做出来了。

714
01:22:58,285 --> 01:23:08,392
这是一个极就是就是很难想象的事情啊，而且最关键他们感觉至少从最后的那个报告里面看起来啊，他们的稳定性还非常的好。

715
01:23:08,392 --> 01:23:11,253
那这个工作它产生的意义是什么呢？

716
01:23:11,253 --> 01:23:14,956
减少了运算量和传输量，而且还有一个好处是什么？

717
01:23:14,956 --> 01:23:23,286
就是如果现在有人啊真的自己的部署模型都知道，我们现在很少会部署那个就是原原来的那个那个那个模型的那个full size。

718
01:23:23,286 --> 01:23:31,943
那个我们一般会做一些量化是吧哈哎就是那个把它那个存储参数做一些量化，这样子在一些低配置的电脑上也可以跑得起来。

719
01:23:31,943 --> 01:23:34,230
那F78训练有个好处是什么呢？

720
01:23:34,230 --> 01:23:37,660
它训练的时候，它很多参数就已经是哎F P8的了。

721
01:23:37,660 --> 01:23:51,648
那这个样子它比那种本来也是是10 16位的，你后面通过一些量化方法来把它做成什么八位量化来说，它它它是native f批发的，它就比你后去做那个八的量化要好很多，这些都会带来很多的提升。

722
01:23:51,648 --> 01:23:59,420
好，我也不过多的深入到细节，但是这里面的每一个东西，大家脑子里面记得啊，我们等会儿会就是总分总一下。

723
01:23:59,420 --> 01:24:06,020
对好，那最后一个m tp这个就是一个更神奇的东西啊，这个皮给我花了不少时间才把我讲懂。

724
01:24:06,020 --> 01:24:06,204
对。

725
01:24:06,204 --> 01:24:12,122
嗯，M T P这个东西叫叫multoken prediction，它它的目的是为让模型看得更远一点。

726
01:24:12,122 --> 01:24:13,047
什么意思啊？

727
01:24:13,047 --> 01:24:17,486
大家知道transformer是letoken prediction，它永远都在预测下一个token。

728
01:24:17,486 --> 01:24:35,980
但是呢这个时候就有学界就有一种想法，就是说那如果我能让他这次预测的时候，不仅预测下一个token，还能预测下两个、三个、四个token，那是不是这个模型在训练的时候他就知道哦，所以我当前看起来我推出这个头Ken的呃概率是最高的，是最优的。

729
01:24:35,980 --> 01:24:45,609
但是我推这个token会导致我下一个偷坑，推出那个token难，但是推出那个来了全局是不优的这让模型看得更远一点，这样子反过来训练这个模型变得更聪明。

730
01:24:45,609 --> 01:24:49,736
这是他最基本的这个训练原理啊，就是让模型学会这个远期规划。

731
01:24:49,736 --> 01:24:52,946
但是同时它会带来一个副产品，这个副产品什么呢？

732
01:24:52,946 --> 01:24:59,518
就是你在训练的时候，他学会了这个，他在推理的时候他也能搞这个事情啊，推理的时候能搞什么事情呢？

733
01:24:59,518 --> 01:25:01,964
他一次性推两个、推三个、推四个都可以。

734
01:25:01,964 --> 01:25:09,137
当然啊在第4个V3里面啊，他们只探索到了就是多推一个，就当于说他相比其他的模型，他一次可以推两个token。

735
01:25:09,137 --> 01:25:15,714
哎，但以前也有这种技术叫speculative decoding是吧哈，但那个是需要额外有一个单独的小尺寸模型。

736
01:25:15,714 --> 01:25:26,169
比如说你有一个大的70B模型，然后你用个7B的小模型去做去去做那个那个specuspecutive的这个这个这个推测，然后让大模型来判断你推的对不对。

737
01:25:26,169 --> 01:25:29,541
哎，他们就用了同样的一个东西去搞定这个事情。

738
01:25:29,541 --> 01:25:33,420
这个事情我第一句写的，我说对创新的执着追，为什么呢？

739
01:25:33,420 --> 01:25:40,841
因为你最后从它的收益上来看哈啊除了这个推理效率提高以外，其实在performance的收益上没有那么高。

740
01:25:40,841 --> 01:25:47,380
但是这个是代表这个deep pc这个团队一个非常特别的一个东西，就是他们很想做新的挑战。

741
01:25:47,380 --> 01:26:03,689
就我刚刚给大家过的所有的最前面这些东西，每一个你单独把它给做出来都是一篇质量很高的配份啊，但是V三这个里面有这么多，而且我只是挑一些我要总分，总要服务我最后那个目标的一些这个这个技术。

742
01:26:03,689 --> 01:26:08,376
其实如果你真的去看那个V 3，光看它的目录都能把你吓死。

743
01:26:08,376 --> 01:26:14,563
他那个目录里面有很多的一些那个纸条目，单个纸条目来说就是一篇高质量paper。

744
01:26:14,563 --> 01:26:16,437
而且质量高到什么程度？

745
01:26:16,437 --> 01:26:22,799
从idea的提出到实验的设计，到工程的软件硬件如何实现，全部给你讲的清清楚楚的啊。

746
01:26:22,799 --> 01:26:30,322
所以说微商其实是一篇深度非常深的paper，阿万其实很快就看完了，阿万没有多少东西很快就看清楚了。

747
01:26:30,322 --> 01:26:34,084
但微商的话就是这是看很久很久，而且非常精彩啊。

748
01:26:34,084 --> 01:26:38,384
好微商的乐趣我说远不支持啊，大家我特特意建大家去看。

749
01:26:38,384 --> 01:26:42,683
但是我前面刚刚我讲了很多，为什么我要选那些技术出来？

750
01:26:42,683 --> 01:26:46,445
什么F P8训练，什么那个要提出新的moe架构是吧？

751
01:26:46,445 --> 01:26:49,897
那些重这东西为什么要做这些工程奇迹？

752
01:26:49,897 --> 01:26:57,244
我们回头去看一看这些关键词哈，什么那个呃share experts，什么那个粗暴的Roter分流算法。

753
01:26:57,244 --> 01:26:58,757
为什么用粗暴呢？

754
01:26:58,757 --> 01:27:01,566
为什么不用之前的分流算法呢？

755
01:27:01,566 --> 01:27:06,537
为什么要要把那个跨节点通信效率做的那么极致，是吧？

756
01:27:06,537 --> 01:27:11,291
还在底层去改了很多的这个汇汇编层面的一些东西。

757
01:27:11,291 --> 01:27:15,181
呃，那个为什么要让训练室的激活内存变小？

758
01:27:15,181 --> 01:27:17,342
为什么要要去减少kv cash？

759
01:27:17,342 --> 01:27:20,151
呃，为什么要减少运输量和传输？

760
01:27:20,151 --> 01:27:25,986
所有这些工程的优化都指向一个点，就是没卡，就是没有高级的卡。

761
01:27:25,986 --> 01:27:31,173
大家看啊就是说H 800跟H100有1个最大的一个区别。

762
01:27:31,173 --> 01:27:32,469
大家看到没有？

763
01:27:32,469 --> 01:27:39,953
互联带宽倒数第三行H 100的互联带宽是双向900GH800是双向400G差了一倍啊。

764
01:27:39,953 --> 01:27:50,727
然后大家知道现在一个节点上八张卡，然后很多节点还要互相串在一起，用ib或者用rocky把它们连在一起，然后节点内用那个nb link来传输这些数据。

765
01:27:50,727 --> 01:27:57,370
但是如果你在节你你你你在节点内的时候就已经比H 100要慢要慢一倍了，你就很尴尬。

766
01:27:57,370 --> 01:28:09,760
然后你去研究它的所有的那些工程上的一些优化，什么呃压缩那个内存在显存占用，减少那个通讯传输量那些东西，每一个都是提升到10% 20%这个样子。

767
01:28:09,760 --> 01:28:14,927
凑起来其实就是为了解决确实是这个nv link的带宽不够用啊。

768
01:28:14,927 --> 01:28:31,257
所以这是当时我在读另外一篇特别精彩的一篇，就是Ben Ben的的那个就是他去聊那个呃那个那个阿万的里面，他给美国人解释，他说如果你真的认真去读完V三的整个实现，你不得不做出判断。

769
01:28:31,257 --> 01:28:43,862
这家公司真的没有那么多的高级卡，要不然我真的想不明白他们为什么要去在工程上搞那么多的奇迹影响啊，然后呢特别有特别有意思是什么？

770
01:28:43,862 --> 01:28:55,752
我在准备这个分享的时候，因为在那个paper里面他有提到说呃，他们那个做那个就是呃做做那个link，他们是呃nv link是160G每秒。

771
01:28:55,752 --> 01:29:03,679
那我就是想问，我说为什么他们的env link是160每秒，这个H 800不是400G每秒啊？

772
01:29:03,679 --> 01:29:17,401
哎然后正好在搜这个的时候，就发现在那个他们的get up上有人提了一个提了个question跟我一样的答案，说哎我能知道为什么你们paper里面写里面H 800的那个N V link只有160G吗？

773
01:29:17,401 --> 01:29:19,012
而不是400G每秒吗？

774
01:29:19,012 --> 01:29:33,326
最下面那个就是那个换方的人啊，还有说400G双向理论值，160是我们测的单向实测，这就意味着他们真的是就是在这个H 800上在干活，然后被这个真实的这个这个物理上限所限制住。

775
01:29:33,326 --> 01:29:47,683
然后所以说才在整个的这个V 2的那个E包括V 3后面的整个的那个那个框架实现上想了那么多的奇迹引巧就是为了降低整个运算过程中的运算量和通信带宽啊，从而在他们的卡上能把这些实验。

776
01:29:47,683 --> 01:29:55,723
因为大家知道训练只是最后跑了一轮，但他们这些研究员平时还要做大量的实验啊，是没有那么多高级卡在供应的。

777
01:29:55,723 --> 01:29:59,911
所以说你真的把这个paper读透了之后，你就会知道所言非假啊。

778
01:29:59,911 --> 01:30:04,099
然后后面有很多问题就是你不解释，你也知道是怎么回事了。

779
01:30:04,099 --> 01:30:08,957
好，然后在这个地方我们把这个阿万的这个整个的这个过去也看完了。

780
01:30:08,957 --> 01:30:15,630
那我们来看看阿万破圈的，我们总结一下阿万破千它的基础和接下去的未来会是什么样子。

781
01:30:15,630 --> 01:30:20,102
那第一个我觉得阿万破圈的基础是真真正正的拿实力说话。

782
01:30:20,102 --> 01:30:24,753
首先它的性能确实强大到不需要说用过的人用懂的都懂，对吧？

783
01:30:24,753 --> 01:30:27,974
第二个就是他解决了困扰整个业界的难题。

784
01:30:27,974 --> 01:30:36,740
就整个业界都在那个什么蒙特卡数搜索啊pm上疯狂的卷，然后各种失败，各种困惑，然他们突然跳出来说不用这样是吧？

785
01:30:36,740 --> 01:30:41,251
第三个就是你在读阿万的时候，你进去了，哇，你说还可以这样吗？

786
01:30:41,251 --> 01:30:42,465
哦，还可以这样吗？

787
01:30:42,465 --> 01:30:49,058
结果读着读着发现阿万背后还有个V 3，然后说我靠这个V三怎么怎么还能这样啊，是不是？

788
01:30:49,058 --> 01:30:53,569
就是这包包括那个大家后面挖掘出来那个就是说deep绕过Q大。

789
01:30:53,569 --> 01:31:12,113
然后当时不是又让nvideo跌了一下嘛，都是那个第一轮过去之后，大家去挖论文的时候发现啊，怎么他们这个地方居然居然绕过了酷达，直接是T X就你就会发现他的实力真的很强，因为它不是一片，它背后有很多solid的这个foundation work在支持这一篇。

790
01:31:12,113 --> 01:31:18,660
然后第四个就是他真的是把任何研究员和工业界想验证的方向都做足了工作。

791
01:31:18,660 --> 01:31:25,267
不仅我自己牛逼，哎，我还告诉你们，拿我产生的高质量的cot去训你们的模型也能变得很牛逼。

792
01:31:25,267 --> 01:31:28,224
而且我还告诉你，不要妄想简单的复制我。

793
01:31:28,224 --> 01:31:32,571
如果你的base model不行，哎，你也搞不定他把这些都工作都做主了。

794
01:31:32,571 --> 01:31:41,613
大家讲如果你作为研究员，你作为那个呃大模型的这个的公司，你看这个是我的这个东西真是呃想我想我所想及我所急是吧？

795
01:31:41,613 --> 01:31:45,439
然后第二个就是彻底的开源，并且他有C端产品可用。

796
01:31:45,439 --> 01:31:59,241
我觉得所有这些点加起来一起是阿万破圈的这个基础，就真真正正的实力，这个是呃阿万破圈之后的未来呢，我觉得这显然哈是给这个全球A行业就是打了一个2025就最好的开局。

797
01:31:59,241 --> 01:32:02,848
当然对于炒股的来说，可能稍微有点这个痛苦啊。

798
01:32:02,848 --> 01:32:10,422
第一个呢就是他们做的那些蒸馏实验，证明了高质量的这个reasoning co t是能够激发现有模型能力的。

799
01:32:10,422 --> 01:32:19,980
只是这么简单的一个事情，我相信有很多的现有的很多的工作，大家都可以重新做一次啊，都可以立马得到提升，就不用搞搞很多。

800
01:32:19,980 --> 01:32:24,974
第二个就是阿万，只是证明左脚踩右脚可行，这是他们产生的第一个工作。

801
01:32:24,974 --> 01:32:33,466
大家可以想一想，我们以往所有的那种范式级的变化产生的时候，是不是包括O万呃，就是恰奇比自己的o one到O 3是不是？

802
01:32:33,466 --> 01:32:39,626
我们完全可以相信deep这个团队可能接下来三个月到半年之内，在R L这个上面还能stea啊.

803
01:32:39,626 --> 01:32:47,994
我们也不知道什么时候会scling到R L的一个头，但至少看起来现在只是一个开始啊，第三个是全球inf终于有事儿干了。

804
01:32:47,994 --> 01:32:52,680
因为之前啊就是大家催了很久的这个AI inf它一直没火起来。

805
01:32:52,680 --> 01:32:57,553
我觉得有一个很大的原因是因为大家找不到值得部署的模型。

806
01:32:57,553 --> 01:33:11,985
大家想一想，如果cloud哦和OpenAI开源，我相信整全球AI inf不是现在这个样子，AI inf现在搞成那个样子，主要就是因为大家我我我自己不模型干嘛呀，你你就比不过cloud，你就比不过这个gt是不是？

807
01:33:11,985 --> 01:33:15,560
所以说就没有实际用途，但是终于有一个对吧？

808
01:33:15,560 --> 01:33:30,296
然后大家可以看到最近像那个我们的那个兄弟厂商啊，那个硅基硅基流动是吧哈，还有还有国外的很多的那些什么fireworks啊什么那些，你你你看他们这个就就是这特别特别特别特别厉害。

809
01:33:30,296 --> 01:33:36,720
对，然后呢第四个就是阿万只是尝试了R L，他们还没有尝试那个可控的inference time。

810
01:33:36,720 --> 01:33:51,303
就是说如果我强行让模型思考更多是吧，我我我去控这个effort，就像大家最近看欧三的那个那个算那个取名方式很错哈，那个什么hi media是吧哈，那个那个那个命名方式就是说想更多，哎，想一番，想少点。

811
01:33:51,303 --> 01:34:00,052
就是就是阿旺还没做了啊，那阿旺做了这个之后，就至少这个部分的这个性能提升，我觉得应该也是一个可以预期的一个事情。

812
01:34:00,052 --> 01:34:07,960
那还有一个就是这个呃long to short，就是这个地方啊是大家一定要我觉得这个概念我觉得学会了还是比较有意思的。

813
01:34:07,960 --> 01:34:23,954
就大家不要把那个reasoning想成是个旁路思考reasoning model并不是说这个模型哦旁边有一个有一个单独一个分支，还在还在思考这边的回答reasoning过程本身和最后的答案都是next token prediction的一部分。

814
01:34:23,954 --> 01:34:32,840
而这个reasoning的过程并不是越长越好，现在有些地方显得比较长，其实恰恰是证明我们的训练效率还不够高。

815
01:34:32,840 --> 01:34:38,672
其实真实的这个到后面的话，其实整个的一个reasoning过程，尤其这个这个在阿旺里面讲的比较少。

816
01:34:38,672 --> 01:34:44,797
如果大家对long short感兴趣，可以去看看K k的那个K1.5那个里面对于long short的这个探索呃比较比较多。

817
01:34:44,797 --> 01:34:51,796
也就是说未来的话其实这个reasoning过程，它其实是会呃long to short这个过程，就reasoning过程不会那么长啊，它会效率更高。

818
01:34:51,796 --> 01:34:53,983
就很快就想到一个该想的一个地方。

819
01:34:53,983 --> 01:35:04,194
但是我这个时候，我当时我就问卡，我说那会不会就有一个有一个最终就是短到没有微森林的，就就这个模型又变回原来那个模型了，就直接把答案说出来。

820
01:35:04,194 --> 01:35:14,639
但是皮克跟我说这个不太可能啊，因为就回到我们前面说的就就是model它本身还是需要more tokens to think啊，那就是说以后可能那个reading它会压缩到一个极限。

821
01:35:14,639 --> 01:35:18,950
对那我们认为可能O 3的其实在O 3的过程中有做这个过程。

822
01:35:18,950 --> 01:35:24,686
哎，这个有个很好的比喻，就是更聪明的模型是学会跳步的，就他不会一步步写出来。

823
01:35:24,686 --> 01:35:27,240
但很牛逼的人解释问题，观察意术啊。

824
01:35:27,240 --> 01:35:32,007
对对对对对对，剧剧剧情对对对对，所以这是未来可能会出现的事情。

825
01:35:32,007 --> 01:35:42,224
然后讲到这里哈，就希望大家还记得我的本职工作哈，我是个搞搞产品的啊，所以我们今天还是要讲一讲阿万对于这个在产品思路上的一些启发。

826
01:35:42,224 --> 01:35:51,760
呃，首先这个就是那个当时24号22号号火爆火爆那个时候，然后当时我们在我跟我跟雨生在一个群里，我分享的一个一个点啊。

827
01:35:51,760 --> 01:35:58,814
呃首先就是我觉得阿万之所以能到一个很重要的事情，就是他有一个非常绝妙的时间差。

828
01:35:58,814 --> 01:36:00,529
这个时间差是什么呢？

829
01:36:00,529 --> 01:36:05,868
就是大家要知道在阿万发布的时候，全世界用过欧万的人是很少的。

830
01:36:05,868 --> 01:36:11,015
因为那个时候欧万是一个付费模型啊，而而且也也不便宜吧，是吧？

831
01:36:11,015 --> 01:36:19,404
那所以说有很多人其实没有用过欧万这个东西，而deep sick只要把它免费，然后让让你让所有人都可以这接用。

832
01:36:19,404 --> 01:36:27,080
也就是说对于很多人来说，他人生中用的第一个reasoning model是deep R one，而不是check gp t的o one。

833
01:36:27,080 --> 01:36:31,732
那这个体验提升一个从0到1的过程就非常夸张。

834
01:36:31,732 --> 01:36:38,820
好，然后另外对于另外一类部分用过o one的用户来说，当时的o one不支持search。

835
01:36:39,020 --> 01:36:43,364
也就是说对于用过欧外的one来说，他用deep c的I他也会觉得很爽啊。

836
01:36:43,364 --> 01:36:46,467
因为他把running跟search加上了，整个场景又扩宽了。

837
01:36:46,467 --> 01:36:51,276
所以说呢相当于是dei one它的发布时间点是在一个非常巧妙的时间差上面。

838
01:36:51,276 --> 01:36:55,620
它对所有的人来说都是一个全新的体验，都是一个从0到1的过程。

839
01:36:55,620 --> 01:36:58,413
所以说每一个人用了之后都会变成自来水。

840
01:36:58,413 --> 01:37:04,464
所以这这也是为什么我在这个过程我特别不屑有心的表达，说什么啊中国水军什么什么之类。

841
01:37:04,464 --> 01:37:12,465
我想想说，天啊，你你真的去看看推特上面真实的美国人的这个用完阿万的反馈，他们的截图，他们用的那些use case非常solid的。

842
01:37:12,465 --> 01:37:18,958
这个东西不是靠一个水军两个字能够能够去解决的啊，它是真正正正有绝佳的产品价值。

843
01:37:18,958 --> 01:37:34,400
用户在用脚投票的整个这持续半个月的help里面，我觉得除了媒体的help以外，用户的表达其实是非常真真诚，非常的这个这样子的东西的对然后这个同时也告诉了我我觉得一个很大的一个启示，就切记地不是终点。

844
01:37:34,400 --> 01:37:39,924
就很多人觉得open I就很难打败啊，现在竞济已经已经那么厉害了，我怎么搞啊？

845
01:37:39,924 --> 01:37:53,562
我我我我做AI这一年半多的时间里面，我我我在很多场合反复都在说这个话啊，就是95%的人现在AI渗透率就5%，另外95%他人生用到的第一款AI应用到底是什么？

846
01:37:53,562 --> 01:38:01,652
大家之前很多人不敢去想这个问题，很多人想就是切的gb t就是我的天花板了，呃，我该怎么去追上前的gdt？

847
01:38:01,652 --> 01:38:07,960
但是deep c和阿文告诉了我们，其实绕开它完全打开一个新的一个市场。

848
01:38:08,080 --> 01:38:14,463
蔡奇接触了这5%的地球人，我完全可以去搞另外的5% 10%的地球人。

849
01:38:14,463 --> 01:38:16,945
他们用的第一款AI用到底是什么？

850
01:38:16,945 --> 01:38:25,456
现在是reasoning model，我觉得还有很多领域，AI领域AI有很多领域会反复发生，而且这个故事去去也发生很多次了，是不是？

851
01:38:25,456 --> 01:38:29,712
Sora hy了一年即实真实的果子被我们国内厂商被被海螺是吧？

852
01:38:29,712 --> 01:38:36,095
被被可林给给给给给摘了，这些都都是同样的故事在在发生，还有很多领域都会在发生。

853
01:38:36,095 --> 01:38:44,165
所以说我觉得大家不用把这个一个非常新兴的行业，一个领域里面，把它好像好像竞争都已经结束了一样。

854
01:38:44,165 --> 01:38:46,883
其实不是的，任何时候上车都不迟。

855
01:38:46,883 --> 01:38:56,200
第三个就是阿万加427，之所以那么火，我觉得本质上是因为阿安加4圈基本上是一个非常简单的一个agent framework。

856
01:38:56,200 --> 01:39:04,342
就说阿万自己的reason他再怎么厉害，这个模型再怎么厉害，他永远只能停留在自己的脑内，脑补他不知道真是些什么样子的。

857
01:39:04,342 --> 01:39:11,845
你把它加上search去了之后，当他获得了外部设计的observation，这件事情才是让阿万加search的体验变得绝佳的一个点。

858
01:39:11,845 --> 01:39:20,626
但是呢很多我觉得我们包我们的同行，大家在观察阿万的时候，忽略这一点，会觉得说阿万厉害是因为他是一个reasoning model，所以他厉害。

859
01:39:20,626 --> 01:39:23,500
我们公司没有model，所以说我们产品做不起来。

860
01:39:23,500 --> 01:39:25,409
我觉得有时候不是这样子的。

861
01:39:25,409 --> 01:39:32,409
如果阿旺我相信他的app在发布的时候没有设那个能力，他现在在全球产生的impact一定会是另外一个样子。

862
01:39:32,409 --> 01:39:35,273
因为有search和媒，这也是一个本质性的区别。

863
01:39:35,273 --> 01:39:42,273
那这个时候我们就可以去想，那阿万已经开源了，那他们加了search那么厉害，那我是不是还能加其他东西呢？

864
01:39:42,273 --> 01:39:44,660
是不是阿万加search，阿万加很多很多。

865
01:39:44,660 --> 01:39:50,136
是我们让更多的web observation都给到这个阿这个model可能就会产生一些不一样东西。

866
01:39:50,136 --> 01:39:51,131
至于是什么呢？

867
01:39:51,131 --> 01:39:58,101
这可能需要行业大家一起探索，但我觉得这个都是属于在产品上给到很多启发的这样子的一些东西。

868
01:39:58,101 --> 01:40:04,739
对然后最后一个环节啊，就是就是就是我本来想说那个回应留言，但我想我不是deep ck，我不法回应。

869
01:40:04,739 --> 01:40:05,569
对我就录呛。

870
01:40:05,569 --> 01:40:11,308
对对，我们来来来去那个就是面对一下就是这段时间流传比较广的这个留言是吧？

871
01:40:11,308 --> 01:40:14,614
第一个就是那个所谓的那个满血版阿万是吧？

872
01:40:14,614 --> 01:40:21,227
满血版我觉得就首先就是美国有些公司啊开了一些坏头，第一个坏头就是那个group对吧对吧？

873
01:40:21,227 --> 01:40:30,102
大家知道gro是一个通过做硬件芯片的，就做硬件架构的算法啊，做硬件硬件架构来加速这个语言模型推理的这么一个公司。

874
01:40:30,102 --> 01:40:38,803
然后呢，当时那个阿万出来之后，group的C O特别help，在那个推Witter上面很快就说我们上线的那个万比官方的推理速度快多。

875
01:40:38,803 --> 01:40:42,913
我什么说这group在我心中他们那个架构不是很不灵活吗？

876
01:40:42,913 --> 01:40:48,842
而且理论上来说，他们那个硬件架构应该是跟那种拉妈like应该是绑的比较死的。

877
01:40:48,842 --> 01:41:05,935
怎么突然就能部署那么大尺寸的moe了，我还有点好奇呢，结果仔细研究他的推论上发的是他他是上了deep R one，但其实他真的部署的是一个deep R one stea拉70D就是就是就是真的难以想象，就是这种公司C又会干这种事情啊，就是各种制嘲help。

878
01:41:05,935 --> 01:41:10,076
然后自从那个之后啊，美国有很多的一平台都开始搞这种故事。

879
01:41:10,076 --> 01:41:13,740
哎，上个上个那种千万32B的也说自己上了2万啊。

880
01:41:13,740 --> 01:41:19,315
对，然后从从此呢大家用户就觉得哎，有时候用感觉好像不好像不是这个样子啊，是吧？

881
01:41:19,315 --> 01:41:27,120
然后就开始冒出来说哦，因为你用的不是阿万满血版，其实阿万没有满血版，2万自自始到终都只有一个版本，就是阿万。

882
01:41:27,120 --> 01:41:37,768
然后剩下那些所有的那些distill版本，大家要知道R one distill叉叉叉叉叉叉才是主语，R one distill是定语，你用的不是R one，你用的就1000万，你用就拉嘛，你没有在用R one。

883
01:41:37,768 --> 01:41:53,660
而最近那个前面half了之后，最近这一周，我最近在一些那个比较活跃的AI社群里面，我也看到有一些那个各种各样行业的同学开始在给那个评测的反馈回来了大家就会发现，虽然说在奔驰mark上我们发现用那个呃做stea那些模型能力都提升了。

884
01:41:53,660 --> 01:42:10,805
但是在真实的场景里面，比如说他们有些人去做角色扮演，但说实话我有点不是特别理解啊，用这个reason model做角色扮演，但但但他们说取得效果非常惊人，学校说学校说效果非常好啊，什么角色扮演写作啊，还有那个A技能，很多很多方向我话都有尝试了。

885
01:42:10,805 --> 01:42:18,546
然后大家普遍都反馈，真正的阿万跟那些disc的版本有本质的区别，在真实任务场景里面差距还是非常非常大的。

886
01:42:18,546 --> 01:42:24,940
哎，所以这是第一个谣言，没有满血版啊，都是行业的一些我觉得一些制造help的人在那乱乱搞。

887
01:42:24,940 --> 01:42:28,642
哎，第二个就是那个经典的那个600万训练成本是吧？

888
01:42:28,642 --> 01:42:36,560
我反复给很多人解释过这个东西啊，然后我们来我们可以来看一看啊啊这是呃这是V 3吧啊这是V 3。

889
01:42:36,720 --> 01:42:52,595
呃，我们搜一下这个cost，哎，就只这一页，V 3里面就是当时我们提到了一个cost，说呃我们在prtraining里面用了那个266万的这个H 800的GPU hours，然后呢再做那个呃上下文上下文增长上用了这么多。

890
01:42:52,595 --> 01:42:58,016
然后在po圈里后训练用了5000个H800的这个GPU hours，最后用了这么多。

891
01:42:58,016 --> 01:43:04,404
我们按照1个小时H 800的租金200元，其实其实说实话这个价格打的有点高。

892
01:43:04,404 --> 01:43:10,600
因为事实上现在H 800的话1个小时其实还可以，也许再拿再再低点价格了。

893
01:43:10,600 --> 01:43:18,537
所以他们估算出来V 3的单次训练成本是500 557万美元，这是他们给出来的。

894
01:43:18,537 --> 01:43:24,931
并且他们在这个就就在自己公布的这个价格的这个下面直接就写了。

895
01:43:24,931 --> 01:43:33,751
就是说lastly我们要再次强调为emphasize，again， 就是说这个training cost只是包含了就是最后的那一轮训练。

896
01:43:33,751 --> 01:43:42,129
因为因为他们的工设计巧妙，工程稳定，所以一次就跑通了，没有出现那种大规模的那种讯封。

897
01:43:42,129 --> 01:43:46,760
所以我一次就训出来，我只我就花了五百多万美元。

898
01:43:46,760 --> 01:43:53,133
然后他说比如说我用了多少天，在什么样子的GPU上面，多少的这个这个十。

899
01:43:53,133 --> 01:44:08,217
好，然后呢这个这个这个这个这个600万没没有包含没有包含什么没有包含那个呃什么之前的研究，哎，各种各样的消融实验架构探索、算法探索、数据准备，没有包含这些哎。

900
01:44:08,217 --> 01:44:17,140
这种类型的说法就是说我一个模型的单次训练成本圈定cost，在学术界和产业里面是非常常见的表达。

901
01:44:17,140 --> 01:44:22,305
就如果你经常看各种新模型的paper，大家都会这么说，而这个东西也没法隐藏。

902
01:44:22,305 --> 01:44:25,137
因为它的整个模型的参数量就摆在那儿。

903
01:44:25,137 --> 01:44:29,136
它训练的token呢17.6T的这个token的数量也是摆在那儿。

904
01:44:29,136 --> 01:44:43,922
只要是懂行的人，根据这个模型的size和它的训练数据集，就你大概是能估算出来他最后需要多少的这个flops的这个东西是一个只要是懂的人都懂，而且在这个行业里面的表达是一个通用表达，要不然呢我们就没法比了。

905
01:44:43,922 --> 01:44:52,477
就如果我们每次去比那个单个模型训练成本，都把上下游所有的成本算进去是吧哈我在那儿买数据花了10万，你在那儿买数据花了20万。

906
01:44:52,477 --> 01:44:58,672
我们公司的清洁工一个月1个月工资5000，呃，我们这个公司有个阿姨是吧八千，那你说这个怎么比呢？

907
01:44:58,672 --> 01:45:02,802
所以行业里面为了能对比，大家通常算的都是单次的这个训练成本。

908
01:45:02,802 --> 01:45:10,620
所以deep这个表达首先没有任何问题，而且他们在自己的在文章里面就估及到可能会有这样子的误解，所以自己已经明确的说了。

909
01:45:10,620 --> 01:45:13,909
不包含什么样子的费用，是什么样子的费用。

910
01:45:13,909 --> 01:45:19,574
所以说我觉得站在deep secret本身的立量上说，他们没有任何作价的这个东西。

911
01:45:19,574 --> 01:45:24,326
完全是因为这一次这个事件破圈，实在破的太快以及破的太广。

912
01:45:24,326 --> 01:45:30,357
然后有大量的这个就是不是这个行业里面的媒体K L参与到这个叙事里面来。

913
01:45:30,357 --> 01:45:36,753
然后大家都知道在一个自己不懂的领域里面去找流量话题最容易的就是什么是吧？

914
01:45:36,753 --> 01:45:46,234
钱人地地缘政治冲突是吧，就是这部就是最容易有流量的，然后大家就很容易就找到这个600万的这个东西，然后各种在那help各种help。

915
01:45:46,234 --> 01:45:52,150
然后到最后的时候你就发现你已经完全没有办法就是真正的跟人去讨论这个话题了。

916
01:45:52,150 --> 01:45:59,216
因为在后面已经完全讨论歪了，没有人在乎最开始deep这ck是怎么说的，他说的是什么，已经没有人在意了。

917
01:45:59,216 --> 01:46:06,611
大家在意的只是说我的屁股坐在哪儿是吧哈哎我想公司那个踩点那些工资高的人我就我就拼命这么去说。

918
01:46:06,611 --> 01:46:09,569
对，所以这个话题到后面就没有什么意义了。

919
01:46:09,569 --> 01:46:23,666
还有就是就是说啊就是那个阿ex森的王是吧哈，就是那个有5万张H 100啊，但实际上就是上面那个是那个就是那个seanalysis那个给出我觉得我觉得这个结果应该是相对说比较公允的啊。

920
01:46:23,666 --> 01:46:29,712
就是在那个呃下面那张图是呃2 2022年就10月7号美国第一次禁运。

921
01:46:29,712 --> 01:46:35,368
在那一次禁运的时候，其实H 800是可以买的，在那次禁运之可以买的。

922
01:46:35,368 --> 01:46:46,860
然后今年1月13号的禁运之后，就是他当时那次那个禁呢，一个是进那个就是呃吉联的那个band位，就带宽还有这个算力，然后框了一个这么框出来。

923
01:46:46,860 --> 01:47:01,889
然后到1月13号的这一次里面呢，它就不仅是限了这个级那个那个那个那个那个那个那个级点，他还把这边这个算力他也有一些有一些哦，不他也把那个就是那个级联速度有一个限制，所以说打的更宽了，白去800也陷进去了。

924
01:47:01,889 --> 01:47:08,218
但是呢那个第其实他有很多的这个合规的H 800是买在一月，肯定是在今年1月13号之前嘛。

925
01:47:08,218 --> 01:47:12,647
所以说呢上面那个股计我觉得是一个比较比较现实的一个估计哈。

926
01:47:12,647 --> 01:47:20,400
就是说呃一万张A版，一万张H 100，然后一万张H 800，然后后面就只能买那个合规的那个H 20的那样那样子的卡。

927
01:47:20,400 --> 01:47:25,650
我觉得这个是比较合理的规则，而且当然这个是一个他们正在产业分析的角度。

928
01:47:25,650 --> 01:47:30,583
但是回到刚刚大家听到我接近2个小时的分享中间，我们讲V三那个部分。

929
01:47:30,583 --> 01:47:35,834
是不是他们为什么要做那么多的工程上的奇迹影巧，那么多的工工程上的优化。

930
01:47:35,834 --> 01:47:42,040
其实如果说他真的手上有那么多的H一板，中间吉林带宽那么高，他完全没必要去做那些优化。

931
01:47:42,040 --> 01:47:48,245
所以说我觉得特长卡这个阿里克商店王的那个表达是一个非常不公正的这样子的一个表达。

932
01:47:48,245 --> 01:47:52,860
哎，然后还有一个就是大家现在在小红书、抖音上到时候能刷到的是吧？

933
01:47:52,860 --> 01:47:56,786
9.9块99付费交流本地部署这四一个阿one。

934
01:47:56,786 --> 01:48:13,927
那大家听今天听完今天这个分享之后就道除非你家里有矿是吧哈，自己自己家里有八张跟一碗，要么你是很难在本地所谓的本地部署的，所以所有那些教你的部署的其实都是一个蒸馏的，什么千文1.5B的，或者7B的，或者一个32B的。

935
01:48:13,927 --> 01:48:19,103
很多电脑可能跑不32B可能就是个7B的一个一个一个still之后的一个千问。

936
01:48:19,103 --> 01:48:21,692
哎，那这个本地部署我觉得本身价值有限。

937
01:48:21,692 --> 01:48:26,564
但是呢我一开始我特别反对啊，只要看到有人在讲那个本地部署，我就说骗子。

938
01:48:26,564 --> 01:48:43,364
哎，但是呢我我后来想了一下啊，我觉得这可能是很好的契机，就是很多人可能之前从来没在自己的电脑上跑过L M，也许借着这个契机，大家学会了怎么在自己的电脑上跑L O M，这这也许也是个马不松的事情啊，所以我现在也对这个事情没有那么反感了啊。

939
01:48:43,364 --> 01:48:52,992
对，然后还有一个就是那个蒸馏和偷窃啊，我本来这里准备了一个尝鲜大论去讲，嗯，首先如果你说是蒸馏举证责任在理是吧，不应该di来回应这个东西。

940
01:48:52,992 --> 01:49:03,323
然后想了很多，然后呢，我觉得续费力都不够强，因为我自己不是专业人士，然后我也我既不能代表OpenAI也不能代表deep sike，所以这个回应会显得非常无力。

941
01:49:03,323 --> 01:49:06,674
结果昨天呢在研究V 3的时候，我有个意外惊喜。

942
01:49:06,674 --> 01:49:15,220
大家记不记得就是我一开始放时间线的时候，12月26号的时候安capacity转发了V 3的那篇paper，大家还记得那个东西吗？

943
01:49:15,220 --> 01:49:24,199
在他转发的那条推Witter下面，他在讲他自己读微生的感受的时候，有一个哥们儿，一个美国老哥跳出来说，我用了一下他们这个模型。

944
01:49:24,199 --> 01:49:26,860
他们这个模型说他是他是恰恰G B G.

945
01:49:27,020 --> 01:49:28,678
那个截图也发的很广。

946
01:49:28,678 --> 01:49:41,760
对，就是这地方说是G P T，然后Andrew卡帕自己回应了这个，然后我发现我不需要产品大论了，因为我说的没有ak k好，而且我的屁股也没有ak k的屁股更适合回答这个问题。

947
01:49:41,760 --> 01:49:46,551
是不是用他的理财来回应，他怎么说的，他怎么回应这个问题的？

948
01:49:46,551 --> 01:49:49,752
他说他们完全没必要那么做，是不是？

949
01:49:49,752 --> 01:49:50,495
It make no sense.

950
01:49:50,495 --> 01:49:59,404
就是你你你也你也没有必要去问这个模型他是谁，因为当你问出这个模型的时候，你就掉入了过度拟人化这个陷阱。

951
01:49:59,404 --> 01:50:12,211
就是有很多的就是那个非我们从业人士啊，大家有时候会把那个切g想的太聪明，后来我比较冲了，就太像一个真实的人呢，总觉得好像他有自己的意识，他知道自己是谁。

952
01:50:12,211 --> 01:50:20,452
我告诉大家，所有的不管是play train的模型还是任何的模型，他脑子里面真的没有我是谁这个概念。

953
01:50:20,452 --> 01:50:32,121
对所有你问出来的呃I ChatGPT我是个什么assistant，全是像ancapacity说的，全是我们构造的那些数据去教会这个模型。

954
01:50:32,121 --> 01:50:38,080
在用户问到对应的话的时候，要这么去说打引号的right answers。

955
01:50:38,080 --> 01:50:49,777
而他说如果说呃如果说你去问这个模型，他说他自己是切gp t商号，他觉得比比他他他说自己不是切gp t还要更好，为什么呢？

956
01:50:49,777 --> 01:50:57,426
因为在他们训V 3的时候，这个世界上已经存在着大量的被切g污染过之后的数据。

957
01:50:57,426 --> 01:51:05,300
也就是说可能网上各种各样地方都有那样子的文本，G D T什什么什么什么之类的。

958
01:51:05,300 --> 01:51:12,612
那作为一个训练的足够好的模型，从概率分布上来说，当用户问你是谁的时候，你确实应该挑概率最高的。

959
01:51:12,612 --> 01:51:17,543
其他机率来说，如果你说起来好像有问题，当然这个不是一个不可解的。

960
01:51:17,543 --> 01:51:25,876
所有的模型做完prtrain之后再做post train，做alignment的过程当中，alignment里面有一个很重要的alignment的方向就做self cotion对吧？

961
01:51:25,876 --> 01:51:29,787
就自我认知，就我们用大量的这个对齐的数据去教会它。

962
01:51:29,787 --> 01:51:36,420
用户问你这个的时候，你回答我是呃我我我是deep si大模型，我是deep v 3，你就不断的去做这个事情。

963
01:51:36,420 --> 01:51:40,407
那对于di来说，他们可能从来都没想过自己会破圈到这个样子。

964
01:51:40,407 --> 01:51:46,947
他们做完V 3之后觉得我操我们这个V三太牛逼了，我要把这些工作开放出去，让大家来来来享受。

965
01:51:46,947 --> 01:51:55,241
他们没有想到有人会在这个方面挑战他，所以他们相信在这方面的alignment和那个potry上面，没有花太大的精力去做这个self cotion。

966
01:51:55,241 --> 01:51:57,314
如果他做了也能解决这个问题。

967
01:51:57,314 --> 01:52:01,940
但是首所以说呢我对这个问题看法，首先我觉得ak已经回应的很好了。

968
01:52:01,940 --> 01:52:10,982
其次就是以后如果有再有人来个截图说哎呀，他怎么那个reasoning这个过程中说他是OpenAI呀，你就丢a的这个给他就ok了啊。

969
01:52:10,982 --> 01:52:14,600
用ak的屁股比谁的屁股都更适合回答这个问题。

970
01:52:14,640 --> 01:52:17,713
对所以说呢今天这个分享呢基本上到这里结束。

971
01:52:17,713 --> 01:52:30,315
然后最后想告诉大家，就是说我在最近这两这两个星期的过程当中哈，就是我一方面在感受这个巨大的创新，对但一方面又看到不管是国内还是国外，有非常多的跳梁小丑一样的人啊，有很多的言论。

972
01:52:30,315 --> 01:52:36,155
就我也会就是有你有时候你越感受这个美好啊，你看那些人你越觉得他们很滑稽，对不对啊？

973
01:52:36,155 --> 01:52:40,151
但是我觉得无所谓，我觉得这些噪音就是就是会随着时间消减。

974
01:52:40,151 --> 01:52:46,624
对，但是我刚刚提到的那个deep ck MaaS v 2、V 3、R one这四个paper，他一定是能够产生持续的这个影响的。

975
01:52:46,624 --> 01:52:54,628
因为就是那种创造的美，你只要真的去体会它，去理解它，就你一定能感受到它就是非常非常的美非常非常的美。

976
01:52:54,628 --> 01:53:05,940
就像去年我们在这里学习study fusion的时候，是不是我列出来的一些paper都很老了，但我回过头一看仍然觉得非常的美啊，所以今天分享基本就到这里啊，谢谢大家。

977
01:53:06,800 --> 01:53:07,058
啊。

978
01:53:07,058 --> 01:53:10,940
这个实在是太太精彩了，我觉得这个。
